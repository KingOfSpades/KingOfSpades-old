[ { "title": "hey for load testing http applications", "url": "/posts/hey-for-loadtesting-http/", "categories": "Commandline", "tags": "cli, macos, devops", "date": "2022-10-25 00:00:00 +0200", "snippet": "shorthey is a HTTP load tester CLI tool to benchmark HTTP requests to a HTTP end-point. Get it at GitHubToday we will be taking a look at a small utility called hey. You can use hey to load test HTTP applications or generate load for a web application. This comes in handy when you want to simulate use or check what your app does when it receives 1000s of requests. Warning: Using a load test on website that you do not own or have permission to test can result in you being banned or blockedInstallationInstallation on macOS with brew is really easy, just run:brew install heyFor other installation options, check out: Hey InstallationUsageSo, we are going to run this against a local docker container, just to be sure that we don’t mess with anyone’s website.Setting up a containerThis is pretty straight forward. Start Docker and run the following command to start it in the background:$ docker run --name webserver -p 8080:80 -d nginxTo make sure it’s running we can check using the docker ps command:$ docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESc2c829348c89 nginx &quot;/docker-entrypoint.…&quot; 3 seconds ago Up 3 seconds 0.0.0.0:8080-&amp;gt;80/tcp, :::8080-&amp;gt;80/tcp webserverNow you can also start a tail on the container to see your load test in action:docker logs -f webserverExample output:172.17.0.1 - - [25/Oct/2022:15:12:18 +0000] &quot;GET / HTTP/1.1&quot; 200 615 &quot;-&quot; &quot;hey/0.0.1&quot; &quot;-&quot;172.17.0.1 - - [25/Oct/2022:15:12:18 +0000] &quot;GET / HTTP/1.1&quot; 200 615 &quot;-&quot; &quot;hey/0.0.1&quot; &quot;-&quot;172.17.0.1 - - [25/Oct/2022:15:12:18 +0000] &quot;GET / HTTP/1.1&quot; 200 615 &quot;-&quot; &quot;hey/0.0.1&quot; &quot;-&quot;Using heySo let’s get testing. hey supports some great arguments like -n (number) the amount of requests to send, -c (concurrently) for the number of workers to run concurrently and -z (Duration) to perform a test over x time.All options can be found on Hey UsageExamplesI’ll be showing some common usagesExample 1: 100 requestsLet’s fire up some requests. First up, 100 request using 5 concurrent workers:$ hey -n 100 -c 5 http://localhost:8080Results:Summary: Total: 0.0448 secs Slowest: 0.0089 secs Fastest: 0.0010 secs Average: 0.0022 secs Requests/sec: 2231.3041 Total data: 61500 bytes Size/request: 615 bytesResponse time histogram: 0.001 [1] |■ 0.002 [34] |■■■■■■■■■■■■■■■■■■■■■■■ 0.003 [60] |■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■ 0.003 [0] | 0.004 [0] | 0.005 [0] | 0.006 [0] | 0.007 [0] | 0.007 [0] | 0.008 [0] | 0.009 [5] |■■■Latency distribution: 10% in 0.0016 secs 25% in 0.0017 secs 50% in 0.0019 secs 75% in 0.0021 secs 90% in 0.0022 secs 95% in 0.0087 secs 99% in 0.0089 secsDetails (average, fastest, slowest): DNS+dialup: 0.0002 secs, 0.0010 secs, 0.0089 secs DNS-lookup: 0.0002 secs, 0.0000 secs, 0.0041 secs req write: 0.0000 secs, 0.0000 secs, 0.0002 secs resp wait: 0.0019 secs, 0.0009 secs, 0.0038 secs resp read: 0.0000 secs, 0.0000 secs, 0.0002 secsStatus code distribution: [200] 100 responsesExample 2: 5 requests with csv outputDump the results to csv output:$ hey -n 1 -c 1 -o csv http://localhost:8080Result:response-time,DNS+dialup,DNS,Request-write,Response-delay,Response-read,status-code,offset0.0087,0.0047,0.0042,0.0001,0.0019,0.0001,200,0.0016Example 3: 30 seconds of requestsNow we are going to use the duration (-z) option:$ hey -z 30s http://localhost:8080Results:Summary: Total: 30.0082 secs Slowest: 0.1231 secs Fastest: 0.0010 secs Average: 0.0070 secs Requests/sec: 7096.5514 Total data: 130967325 bytes Size/request: 615 bytesResponse time histogram: 0.001 [1] | 0.013 [199692] |■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■ 0.025 [12165] |■■ 0.038 [868] | 0.050 [159] | 0.062 [47] | 0.074 [11] | 0.086 [9] | 0.099 [1] | 0.111 [1] | 0.123 [1] |Latency distribution: 10% in 0.0035 secs 25% in 0.0045 secs 50% in 0.0061 secs 75% in 0.0085 secs 90% in 0.0115 secs 95% in 0.0140 secs 99% in 0.0212 secsDetails (average, fastest, slowest): DNS+dialup: 0.0000 secs, 0.0010 secs, 0.1231 secs DNS-lookup: 0.0000 secs, 0.0000 secs, 0.0069 secs req write: 0.0000 secs, 0.0000 secs, 0.0025 secs resp wait: 0.0069 secs, 0.0009 secs, 0.1230 secs resp read: 0.0001 secs, 0.0000 secs, 0.0431 secsStatus code distribution: [200] 212955 responsesLimiting requestsNow, as you can see, we just fired off 212955 requests. That might be a bit of overkill. To prevent this, we can use the -q (Rate limit) and -c option. We will perform a load test of 5 seconds and use -c to limit ourselves to 2 workers, and we will set a limit of 5 request per second per worker:$ hey -z 5s -c 2 -q 5 http://localhost:8080This results in 50 requests being made:...Status code distribution: [200] 50 responsesWrapping upSo that’s hey. A super simple HTTP load tester. You can use hey to do some advanced things like posting code, testing authentication and other things. Take a look at the readme" }, { "title": "Build-log: Montsinger Rebound-S", "url": "/posts/building-the-montsinger-rebound-s/", "categories": "Keyboard", "tags": "", "date": "2022-08-27 00:00:00 +0200", "snippet": "The Rebound-S by Montsinger is a 60% case compatible ~40% keyboard ortholinear keyboard with an ergonomically-friendly 7° typing angle. It differs from the Rebound because it has a staggered contour. The Rebound’s have some great customisation options like spot for a dedicated for an EC12 encoder and some extra keys located between the two halves of the keyboard. The PCB also allows you to build the keyboard with a choice of switches (Choc or MX style) and microcontrollers letting you choose which controller to use.For my build I went with the nice!nanofor wireless support. I also decided not to install all keys (because I don’t use them all) and to use M2 screws and bolts to get a very low profile keyboard.This is more of a build log than a complete guide. You can use it to check if you’d like to build your own keyboard but it’s by no means complete. The official buildguide is over at http://docs.montsinger.netParts-listTo build this keyboard you will need the following, from the Montsinger website you will need: Montsinger Rebound S PCB Montsinger Rebound S Plate Montsinger Small adapter boardYou will need to provide the following parts yourself: A nice!nano controller A small 100mah battery (or bigger) Choc or MX switches (builders choice, the Rebound supports both) Keycaps of choiceOptional parts: A EC12 encoder and knob Mill Max Low Profile Sockets, highly recommended, to make the nice!nano removableInstalling the nice!nanoI decided to start by installing the controller because this keyboard does not have native hot swappable switch support. By installing the controller first I could test the PCB first before adding switches save myself a lot of troubleshooting after installing the switches. Because I opted to use a nice!nano I had to use the Small adapter bord (provided by Montsinger) to install my controller on to the keyboard.Many instructions have been written on how to socket your controller, so I’m just going to refer to the How do I socket a microcontroller? by splitkb.com.Setting up the pins on the sockets on the adapter board:Preparing the socket pins on the milmaxPreparing the nice!nano for soldering. I put some isolation tape in between the nice!nano and the sockets to prevent the solder from leaking in to the socket. This way, the controller is easily removable. A lot of people on Discord let me know they don’t do this and never had any issues, but the last two controllers I socketed did not want to come off after, so better safer than sorrow.Adding a piece of electrical tape prevents the solder from seeping troughNice and soldered:And un socketed:Then just solder the sockets to the adapter board, put it on the PCB and connect the rest:The Nice!Nano on the Montsinger AdapterInstalling switchesI started by getting the EC12 in place that I wanted to use:The EC12 encoder on the center with the pins bent inI noticed the plate did not want to align nicely on the PCB after installing the EC12 encoder. To fix this I bent the pins of the encoder inwards after soldering it and I filed down the top plate a bit:Then I simply added the switches to the top plate:And aligned it on the PCB:Then just flip it over and solder on the switches.Adding the batteryInitially I thought about adding the battery between the plates. But after putting on all the switches I needed I saw that there was a nice space left on the left and right corners of my board. So I decided to but a battery there and route the cables troug a switch hole. I super glued a small on-off switch on the the underside of the PCB to act as a power-switch.With some cramming I got my powercables routed through two connectors on the PCB that are not in use (not sure how safe this is but it works)Once on the other side I connected them up to my nice!nano:Whith everyting in place I tugged away the cables:Baseplate and keycapsThe last step was to add the baseplate. This is pretty straight foward. To minimize heigt I decided to use short M2 screws with M2 bolts in between as stand offWhen everything is put together, it looks like this:Software and layoutI went with a simpel layout. I cloned the repo from https://github.com/Gorbataras/zmk-nn-rebound and gave it my own spin over at https://github.com/KingOfSpades/zmk-nn-rebound.Tip, to enable the use of the rotary encoder you will need to enable them in config/rebound_v4.conf:# Uncomment these two lines to add support for encodersCONFIG_EC11=yCONFIG_EC11_TRIGGER_GLOBAL_THREAD=yYou can add a binding to the encoder per layer on the keyboard like so:sensor-bindings = &amp;lt;&amp;amp;inc_dec_kp C_VOLUME_UP C_VOLUME_DOWN&amp;gt;;An example can be found here: https://github.com/KingOfSpades/zmk-nn-rebound/blob/master/config/rebound_v4.keymap#L81Closing thoughtsThe Montsinger Rebound S is a fun build with lot’s of custom options. It’s my first choc low profile keyboard and it works great! It’s also pretty affordable to build! I decided to go with an EC12 encoder that was really low-profile. This does remove the “click” feature found on other encoders but I don’t feel like I’m missing allot." }, { "title": "Configuring default Project creation in Openshift", "url": "/posts/customizing-project-creation-openshift/", "categories": "EX280", "tags": "openshift, kubernetes, ex280", "date": "2022-02-27 00:00:00 +0100", "snippet": "In this blog we will have a look at “Configuring project creation” in an Openshift cluster. We will: Create a Project Template Add resources like a limit-range to the template Disable project self-provisioningAs always. We will be doing all the examples in a CRC (Code Ready Containers) environment.Project templateWhen creating a new project in Openshift (a namespace) the API query’s the default template that is in use by the cluster. We can however change this to better suit our needs.By creating a project template and adding resources to it we can setup new Projects to be in line with our workflow and we can apply limits on creation.Creating a templateTemplates are stored in the namespace openshift-config as template.template.openshift.io objects. To create a new template we can use the special oc adm command:$ oc adm create-bootstrap-project-template -o yaml &amp;gt; our-template.yamlThis template will include some basic things like: Creating a admin role-binding to the user that creates the project Setting up parameters like PROJECT_REQUESTING_USERCustomizing our templateAdding custom object is done by adding to the -objects array. Here we can add object’s like LimitRange, Quota and other Openshift resources. Tip: When adding to the template validate the object’s first by creating them. Otherwise you might get syntax error’s when creating new projectsLet’s change a few things in our template:# our-template.yamapiVersion: template.openshift.io/v1kind: Templatemetadata: creationTimestamp: null name: our-templateobjects:- apiVersion: v1 kind: LimitRange metadata: name: &quot;${PROJECT_NAME}-resource-limits&quot; spec: limits: - type: Container default: cpu: 50m- apiVersion: project.openshift.io/v1 kind: Project metadata: annotations: openshift.io/description: ${PROJECT_DESCRIPTION} openshift.io/display-name: ${PROJECT_DISPLAYNAME} openshift.io/requester: ${PROJECT_REQUESTING_USER} creationTimestamp: null name: ${PROJECT_NAME}-from-template spec: {} status: {}parameters:- name: PROJECT_NAME- name: PROJECT_DISPLAYNAME- name: PROJECT_DESCRIPTION- name: PROJECT_ADMIN_USER- name: PROJECT_REQUESTING_USERIn this yaml we have: added to the project name -from-template. Every new project that is created will now be called PROJECT-from-template Added a LimitRange with the name ${PROJECT_NAME}-resource-limits to all new projects that sets a default cpu limit of 50m Removed the default admin role bindingApplying our custom templateRemember to create the template in openshift-config:$ oc apply -f our-template.yaml -n openshift-configtemplate.template.openshift.io/our-template created To make this template the default we need to add it at the end of project.config.openshift.io/cluster:$ oc edit project.config.openshift.io/cluster Change the last line from:spec: {}To:spec: projectRequestTemplate: name: our-templateNow we can check out our template:$ oc get templates.template.openshift.io -n openshift-configNAME DESCRIPTION PARAMETERS OBJECTSour-template 5 (5 blank) 2No we need to wait a bit for the cluster to pick up the change. You can monitor this by checking the api pods:$ oc get pods -n openshift-apiserverAME READY STATUS RESTARTS AGEapiserver-b47db7bc4-x79sm 0/2 Pending 0 41sapiserver-ccc6bf7b5-gbbq2 2/2 Terminating 0 125mOnce the new pods are up and running we can test out our new template.Creating a new project with our templateOk check, new config is online? Let’s create a project:$ oc new-project template-test-projectNow using project &quot;template-test-project-from-template&quot; on server &quot;https://api.crc.testing:6443&quot;.$ oc get limitrangeNAME CREATED ATtemplate-test-project-resource-limits 2022-02-27T19:38:12ZDisabling project self-provisioningLetting users create new projects is a main principle of the DevOps setup of any cluster. There might however be situations where you don’t want users to create their own projects. You could enforce project creation with a GitOps pipeline and ensure that no rouge projects are created from the CLI or web-interface.Patching the self-provisioner roleBy default all authenticated uses are able to create new projects. To disable this we can patch this binding with:$ oc patch clusterrolebinding.rbac self-provisioners -p &#39;{&quot;subjects&quot;: null}&#39;After this, users can no longer create projects:$ oc new-project test-projectError from server (Forbidden): You may not request a new project via this API. Auto update: This patching will work until the cluster is updated. To make this permanent follow the instructions in the RedHat Openshift documentationCreating a provisioning roleIn certain scenarios you might still want some users to create projects. All users with the clusterolebinding cluster-admin can still create projects. For users with less privileges we will create a group ProjectCreators:$ oc adm groups new ProjectCreators$ oc adm policy add-cluster-role-to-group self-provisioner ProjectCreators$ oc adm groups add-users ProjectCreators JimNow all members of the group can create projects.Wrapping upThis was a really simple demo of changing the default project template to something that fits our needs better.I hope this post has helped you. Check out my other EX280 related content on my EX280 page" }, { "title": "Controlling Ingress with Openshift Network Policy&#39;s", "url": "/posts/controlling-network-access-in-openshift/", "categories": "EX280", "tags": "openshift, kubernetes, ex280", "date": "2022-02-27 00:00:00 +0100", "snippet": "This blog will go in to the “software defined networking” of “Configure networking components” objective of the EX280 exam from RedHat. In this post we will: Traffic to pods The types of Network Policy’s we can create Create a Network Policy based on a application label This post focuses on Ingress (incoming traffic). You can also create Egress policy’s to manage outgoing trafficAs always. We will be doing all the examples in a CRC (Code Ready Containers) environment.Traffic to podsAs explained in my post about Services and Routes pods are accessed in the cluster by using services. We can filter traffic to these services using Network Policy’s. These can allow traffic based on different ‘keys’ called identifiers. By default no traffic is blocked to a service and you can not block traffic from a pod to itself. When you add a Network Policy all traffic is blocked by default.Also, good to keep in mind is that Network Policy’s are cumulative. Meaning they won’t cancel each other out.Types of Network Policy IdentifiersYou can use three (3) ways to block or allow traffic to your Service, you can filter: Pods: by using a label (podSelector). You can allow traffic from certain pods in your cluster. Namespace: by using the label (namespaceSelector) you can allow access from a given namespace in the cluster IP Blocks: by using the IP (ipBlock) you can block or allow IPv4 addresses to access a serviceExample of a Network PolicyA {networkPolicy} can look like this:kind: NetworkPolicyapiVersion: networking.k8s.io/v1metadata: name: allow-from-labelspec: podSelector: matchLabels: app: nginx ingress: - from: - podSelector: matchLabels: access-to-service: &quot;true&quot;In this example: We create a network policy called allow-from-label It will work on the pods that are labeled as app: nginx It will allow access to our service if the pod that access our service has a label access-to-service which is set to trueTo create a IPBlock type Network Policy we would use:kind: NetworkPolicyapiVersion: networking.k8s.io/v1.... ingress: - from: - ipBlock: cidr: 172.17.0.0/16 except: - 172.17.1.0/24To create a namespace type Network Policy we would use:kind: NetworkPolicyapiVersion: networking.k8s.io/v1.... ingress: - from: - namespaceSelector: matchLabels: project: myprojectCreating a policyTo test if we can block traffic to a pod using a Network Policy we will spin up two (2) apps called server and client in our namespace called restricted-network. We will secure access to our server service by creating a Network Policy called access-policy:Creating the project and apps:$ oc new-project restricted-network$ oc new-app --name client --image bitnami/nginx$ oc new-app --name server --image bitnami/nginxNow that we have created the server app we can run a curl command using oc exec with our client pod and check if we can connect to it. But first we have to expose the server:$ oc expose service/server$ oc get routeNAME HOST/PORT PATH SERVICES PORT TERMINATION WILDCARDserver server-restricted-network.apps-crc.testing server 8080 NoneCheck, our target will be the service: server. Lets curl it:$ oc exec -it client-76ccdb697d-n2xqp -- curl -v server:8080 | grep HTTP&amp;gt; GET / HTTP/1.1&amp;lt; HTTP/1.1 200 OKGreat! We can set up a connection. Now lets see what happens when we create the following network policy:# allow-from-label.yamlkind: NetworkPolicyapiVersion: networking.k8s.io/v1metadata: name: allow-from-labelspec: podSelector: matchLabels: policy: &quot;true&quot; ingress: - from: - podSelector: matchLabels: access-to-service: &quot;true&quot;And let’s apply it:$ oc apply -f allow-from-label.yamlnetworkpolicy.networking.k8s.io/allow-from-label configured $ oc get networkpolicies.networking.k8s.ioNAME POD-SELECTOR AGEallow-from-label deployment=server 5s Now we only need to add a label to our server to link this Network Policy. We will apply the label: policy: &quot;true&quot;:$ oc label pod server-68ff6d4bfd-prd4w policy=truepod/server-68ff6d4bfd-prd4w labeledLet’s test our access again with the -m flag (--max-time), otherwise we will be waiting a long time:$ oc exec -it client-76ccdb697d-n2xqp -- curl -v -m 3 server:8080 | grep HTTPcommand terminated with exit code 28 No we will add the label access-to-service: &quot;true&quot; to our pod client and try again:$ oc label pod client-76ccdb697d-n2xqp access-to-service=truepod/client-76ccdb697d-n2xqp labeled$ oc exec -it client-76ccdb697d-n2xqp -- curl -v server:8080 | grep HTTP&amp;gt; GET / HTTP/1.1&amp;lt; HTTP/1.1 200 OKAnd thats a simple demo of adding a Network Policy, applying it to a pod and granting access to it by adding a label to a pod.Wrapping upControlling ingress traffic to services and pods gives you (and your developers) a great way to increase security in the cluster. By segmenting access based on labels or namespaces you can easily isolate important services from the rest of the cluster.I hope this post has helped you. Check out my other EX280 related content on my EX280 page" }, { "title": "Exposing services with routes and SSL", "url": "/posts/exposing-services-with-routes-and-ssl/", "categories": "EX280", "tags": "openshift, kubernetes, ex280", "date": "2022-02-26 00:00:00 +0100", "snippet": "This blog will go in to “Configure networking components” objective of the EX280 exam from RedHat. In this post we will: Have a look at services Expose a service with a URL Check out the types of routes we can create Creating a route to a service that is encrypted with SSLAs always. We will be doing all the examples in a CRC (Code Ready Containers) environment.Understanding servicesLets start with the last component when connecting to an application that is running in OpenShift, the pod where the application is running. How does it get here? When you create a application using oc new-app the cluster automatically creates a service for you (checkout oc explain service).A service acts as a load balancer for your pod(s) running your application. This way, no matter how many pods you have running (or where they are running) there is a single service object that can be used to access them.flowchart LR subgraph Internet Client end subgraph Openshift Client --&amp;gt;|Public URL| Route Route --&amp;gt; Service subgraph Namespace Service --&amp;gt; Pod01 Service --&amp;gt; Pod02 Service --&amp;gt; Pod03 end endServices in detailA service {object} in Openshift can look like this:apiVersion: v1kind: Servicemetadata: annotations: openshift.io/generated-by: OpenShiftNewApp labels: app: nginx app.kubernetes.io/component: nginx app.kubernetes.io/instance: nginx name: nginxspec: clusterIP: 10.217.4.22 clusterIPs: - 10.217.4.22 internalTrafficPolicy: Cluster ipFamilies: - IPv4 ipFamilyPolicy: SingleStack ports: - name: 8080-tcp port: 8080 protocol: TCP targetPort: 8080 - name: 8443-tcp port: 8443 protocol: TCP targetPort: 8443 selector: deployment: nginx sessionAffinity: None type: ClusterIPstatus: loadBalancer: {}In this example we can see: That the cluster ip of this service (the IP that can be used to reach the pods) is 10.217.4.22 That this route will send traffic to deployments with a selector (deployment: nginx) The type of this service is ClusterIP. This is the default. There are more types, check them out at the Kubernetes Service Types pageUnderstanding RoutesWe can access the pods using a service with an IP. Great, but no one (hopefully) is typing IP’s in to their browser on a daily basis to get to your app. That’s where routes come in to play.With a route we can expose our service with a http URL like amazing-app.ourcluster.com. And if we configure Openshift even further we can make things available on base domains like amazing-app.com.Routes are used by the central cluster ingress (the point where all the traffic comes in) to route (pun!) the traffic to the right service.expose vs routeThere are two (2) ways to create a route. oc expose and oc create route. When we talk about creating a route we often jump to the latter because it has ‘route’ in it’s name. It is even the one we should be using because oc create route is used to create Secure routes. And here lies the difference in the two. When using expose we can expose our service in a number of different ways which include using a http hostname. When using oc create route we can create a secure route that uses TLS/SSL to encrypt the traffic.Types of secure routesWhen using oc create route we have to choose between a set of different types of routes, these are: Edge: This will expose a route on the edge of your cluster. The route will contain the SSL certificate files. Once the traffic goes to the service it will no longe be encrypted Passtrough: This will connect you pod directly to the cluster Ingress. The SSL certificate will be stored in the pod Reencrypt: Is a combination of Edge and Passtrough. It will re encrypt the traffic once it is passed the IngressExposing an applicationWe will now move on to some examples, we will: Create a route using expose to create our route on http We will create a safe edge route using a SSL certificate You can find instructions on how to create a Self Signed Certificate hereCreating a routeWe will create a route called unsecure-route on our app called unsecure-app in the namespace: this-is-insecure. The route will be insecure-app-this-is-insecure.apps-crc.testing because we are on CRC. Let’s get started:Creating a project and a simple app:$ oc new-project this-is-insecure$ oc new-app --name insecure-app --image bitnami/nginx--&amp;gt; Found container image 2309fdc (15 hours old) from Docker Hub for &quot;bitnami/nginx&quot; * An image stream tag will be created as &quot;insecure-app:latest&quot; that will track this image--&amp;gt; Creating resources ... imagestream.image.openshift.io &quot;insecure-app&quot; created deployment.apps &quot;insecure-app&quot; created service &quot;insecure-app&quot; created--&amp;gt; Success Application is not exposed. You can expose services to the outside world by executing one or more of the commands below: &#39;oc expose service/insecure-app&#39; Run &#39;oc status&#39; to view your app.Creating our route using expose:$ oc expose service/insecure-app \\ --name unsecure-route \\ --hostname insecure-app-this-is-insecure.apps-crc.testingroute.route.openshift.io/unsecure-route expos Testing our routeTesting can be done by spinning up another container or using the oc debug command:$ oc debug insecure-app-7d8667f64b-cvkcz(pod) $ curl -v insecure-app-this-is-insecure.apps-crc.testing .... &amp;lt; HTTP/1.1 200 OK &amp;lt; server: nginx &amp;lt; date: Sat, 26 Feb 2022 15:20:53 GMT &amp;lt; content-type: text/html &amp;lt; content-length: 615 &amp;lt; last-modified: Tue, 15 Feb 2022 23:05:56 GMT &amp;lt; etag: &quot;620c31d4-267&quot; &amp;lt; x-frame-options: SAMEORIGIN &amp;lt; accept-ranges: bytes &amp;lt; set-cookie: cef860fd45f3b8c73246fd4b31240250=22b324be48072691fec3f3ebe83c8473; path=/; HttpOnly &amp;lt; cache-control: private ....And that’s that!Creating a secure routeNow we will create a route but we will secure it with a TLS/SSL cert. The route will be called secure-route with the hostname secure-app-this-is-secure.apps-crc.testing in our project this-is-secure with the app secure-app:Creating a project and app:$ oc new-project this-is-secure$ oc new-app --name secure-app --image bitnami/nginxNow we will create the secure route:$ oc create route edge secure-route \\ --service secure-app \\ --hostname secure-app-this-is-secure.apps-crc.testing \\ --key secure-app.key \\ --cert secure-app.crt Testing our secure routeLet’s check it using oc debug PODNAME, don’t forget to add the -v (verbose) and -k (insecure) flag’s to the curl command otherwise you will not see the protocol and it will throw up an error because the SSL certificate is not signed by a valid CA:$ oc debug secure-app-bccd9557b-s2nd4(pod) $ curl -vk https://secure-app-this-is-secure.apps-crc.testing * SSL certificate verify result: self signed certificate (18), continuing anyway. &amp;gt; GET / HTTP/1.1 &amp;gt; Host: secure-app-this-is-secure.apps-crc.testing &amp;gt; User-Agent: curl/7.64.0 &amp;gt; Accept: */* &amp;gt; * TLSv1.3 (IN), TLS handshake, Newsession Ticket (4): * TLSv1.3 (IN), TLS handshake, Newsession Ticket (4): * old SSL session ID is stale, removing &amp;lt; HTTP/1.1 200 OK &amp;lt; server: nginx &amp;lt; date: Sat, 26 Feb 2022 15:29:16 GMT &amp;lt; content-type: text/html &amp;lt; content-length: 615 &amp;lt; last-modified: Tue, 15 Feb 2022 23:05:56 GMT &amp;lt; etag: &quot;620c31d4-267&quot; &amp;lt; x-frame-options: SAMEORIGIN &amp;lt; accept-ranges: bytes &amp;lt; set-cookie: 0e799158437fe6ddd46e0e7a82dd3c25=25f02ff58528846c979c113d77ea289e; path=/; HttpOnly; Secure; SameSite=None &amp;lt; cache-control: private.... Wrapping upThe way that services and routes play together is a fundamental building block of exposing your applications to the outside world in a safe way. The thing that I found so confusing is that oc expose creates routes just like oc create route but in the insecure way.I hope this post has helped you. Check out my other EX280 related content on my EX280 page" }, { "title": "Manage users and policies, groups and permissions", "url": "/posts/setting-up-auth-and-users/", "categories": "EX280", "tags": "openshift, kubernetes, ex280", "date": "2022-02-20 00:00:00 +0100", "snippet": "This blog will cover the “Manage users and policies” objective of the EX280 exam from RedHat. In this post we will: Configure the HTPasswd identity provider for authentication Create and delete users Modify user passwords Modify user and group permissions Create and manage groupsWill also sprinkle in a little bit from “Manage users and policies” with: Define role-based access controls Apply permissions to usersThe most easy way to try OpenShift is by using CRC. In this case this gives as an advantage because HTPasswd is already set up. We will however be configuring it from the ground up using the example provided by the OpenShift documentation 1.Setting up HTPasswd AuthenticationOne of the simplest way to authenticate users to a cluster is by using the HTPasswd provider. This is based on a text based secret containing a username:password key-pair. It’s easy to set up and understand.Creating the HTPasswd fileCreating a new HTPasswd file can be done in a single command from the command-line:$ htpasswd -c -B -b FILENAME USERNAME PASSWORDLet create our first user with username admin and password … dunder:$ htpasswd -c -B -b htpasswd-file Michael dunderAdding password for user MichaelAdding usersAfter creating the htpasswd file we can drop the -c (create) flag and add some more users:$ htpasswd -B -b htpasswd-file Pam secret01 Adding password for user Pam$ htpasswd -B -b htpasswd-file Dwight secret02$ htpasswd -B -b htpasswd-file Jim secret03 Important: Usernames and passwords are case sensitiveAnd let’s have a look at our file:$ cat htpasswd-fileMichael:$2y$05$f2SD9CoUnLzqkA.AgTVToOb6fSKhmN.5xwHqq/Cz/zUZ4ZSXqsyzePam:$2y$05$fRR.5EmSaDGd1rMtAygWxexpuiMGnZJOgk0Oo.kuocyKtKoin5Z0eDwight:$2y$05$EKp1MLW/anaJ1R2wKpAkju6oPZvxV47tTtTq8KKp7x.cjFeOTke5uJim:$2y$05$k1Nlh3ZhqY8E6wK.v1exfOuieLkmZT2MRwFFxVuYZ8KQZ3xcLHWg.Applying secret to the clusterIn order to use our htpasswd file we need to make it available in the cluster as a secret. I wrote about creating secrets before here.We will create a secret called htpasswd-source in the cluster with the content of our htpasswd file. This has to be done in the project openshift-config:$ oc create secret generic htpasswd-source \\ --from-file htpasswd=htpasswd-file \\ --namespace openshift-configsecret/htpasswd-source createdSetting up the identity providerNow that we have the secret in place we can create our identity provider. We will do this with the template thats available from the OpenShift Documentation 1 :apiVersion: config.openshift.io/v1kind: OAuthmetadata: name: clusterspec: identityProviders: - name: custom_htpasswd_provider mappingMethod: claim type: HTPasswd htpasswd: fileData: name: htpasswd-sourceBy applying this yaml to the cluster we will: Create a OAuth Identity provider called custom_htpasswd_provider With the source secret htpasswd-source$ oc apply -f custom_htpasswd_provider.yaml \\ --namespace openshift-configoauth.config.openshift.io/cluster configuredIt might take a while but after some syncing in you cluster your new auth provider should be online. You can check this with oc get oauth:$ oc get oauth -o yamlapiVersion: v1items:- apiVersion: config.openshift.io/v1.... spec: identityProviders: - htpasswd: fileData: name: htpasswd-source mappingMethod: claim name: custom_htpasswd_provider type: HTPasswd....Viewing users and logging inAfter getting our new authentication provider up and running we can test it by logging in with one of our new users. But first, lets take a look at the users we have:$ oc get usersNAME UID FULL NAME IDENTITIESdeveloper 623cd251-b25b-44b5-a00e-67f311029588 developer:developerkubeadmin 06238f0b-4f58-45f2-9b61-94b482bb4b74 developer:kubeadmin As you can see our new users are not yet listed. This is because they will be created after they log in. For example:$ oc login -u Pam https://api.crc.testing:6443Authentication required for https://api.crc.testing:6443 (openshift)Username: PamPassword:Login successful.Switch back to a user with admin rights and check te users again:$ oc login -u kubeadminLogged into &quot;https://api.crc.testing:6443&quot; as &quot;kubeadmin&quot; using existing credentials.$ oc get usersNAME UID FULL NAME IDENTITIESPam cfe773a0-e0e2-40e1-bb5f-799db1ceaeb7 custom_htpasswd_provider:Pamdeveloper 623cd251-b25b-44b5-a00e-67f311029588 developer:developerkubeadmin 06238f0b-4f58-45f2-9b61-94b482bb4b74 developer:kubeadminWe can see that Pam was created and that her identity is provided by custom_htpasswd_provider:Pam. At this point we can see that everything works. I would however advise you to test all users that you have created. This will prevent errors from showing when we want to add users to a group.Creating groupsCreating groups is actually quite strait forward with the oc adm groups command. First off, lets create a group called managers:$ oc adm groups new managersgroup.user.openshift.io/managers createdAnd let’s add Micheal to that group:$ oc adm groups add-users managers Michaelgroup.user.openshift.io/managers added: &quot;Michael&quot;$ oc get groupsNAME USERSmanagers Michael It’s that easy. We can also create a group and add users at the same time:$ oc adm groups new sales Jim Dwight $ oc adm groups new sales Jim Dwightgroup.user.openshift.io/sales created $ oc adm groups new reception Pamoc get groupsNAME USERSmanagers Michaelreception Pamsales Jim, DwightIt’s that easy!Assigning PermissionsNow it’s time to assign some permissions. We do this by using the oc adm policy command. By default a user can create projects and manage objects in that project. We can assign permissions to a user or a group. We are going to give Michael full permissions to the cluster by giving him cluster-admin cluster role:oc adm policy add-cluster-role-to-user cluster-admin Michaelclusterrole.rbac.authorization.k8s.io/cluster-admin added: &quot;Michael&quot;Now we will create a project as Micheal and give the sales group permissions to it:$ oc new-project sales$ oc adm policy add-role-to-group edit sales \\ --namespace salesclusterrole.rbac.authorization.k8s.io/edit added: &quot;sales&quot;Take note of the --namespace flag in this command. This will bind the permissions to the namespace sales.We also want to give the reception groups view permissions to the namespace sales:$ oc adm policy add-role-to-group view reception --namespace salesclusterrole.rbac.authorization.k8s.io/view added: &quot;reception&quot;To view all bound permissions to a namespace we can use:$ oc describe rolebinding.rbac -n sale For example:$ oc describe rolebinding.rbac -n sales | grep reception -B 9Name: viewLabels: &amp;lt;none&amp;gt;Annotations: &amp;lt;none&amp;gt;Role: Kind: ClusterRole Name: viewSubjects: Kind Name Namespace ---- ---- --------- Group receptionFor a full list of roles and permissions check out the RedHat OpenShift documentation on Roles.Optional: Removing the default kubeadminA great best practice is to remove the default kubeadmin user. However, we should only do this after assigning the cluster-role cluster-admin to a user that we have testes. To make sure of this let’s check the binding:$ oc describe rolebinding.rbac | grep ClusterRole -A 5 Kind: ClusterRole Name: adminSubjects: Kind Name Namespace ---- ---- --------- User Michael....Check! Now we can delete the default kubeadmin user 2 :$ oc delete secrets kubeadmin -n kube-systemsecret &quot;kubeadmin&quot; deletedWrapping upUnderstanding how user creation, authentication and permissions works is a basic principle of working with cluster. Is is however often overlooked because there are so many pre configured ways out there to get this working (like integration with Azure or a direct LDPA sync). It’s important have a firm understanding of Users, Groups and Permissions in order to be proficient OpenShift Admin.I hope this post has helped you. Check out my other EX280 related content on my EX280 page https://docs.openshift.com/container-platform/4.6/authentication/identity_providers/configuring-htpasswd-identity-provider.html &amp;#8617; &amp;#8617;2 https://docs.openshift.com/container-platform/4.6/authentication/remove-kubeadmin.html#removing-kubeadmin_removing-kubeadmin &amp;#8617; " }, { "title": "Switch iTerm profile when running Vim", "url": "/posts/switching-iterm-profile-on-job/", "categories": "Commandline", "tags": "vim, iterm2, macos", "date": "2022-02-08 00:00:00 +0100", "snippet": "I love using iTerm2 and Vim on my Mac. Today we are going to have a look at Profile Switching feature that iTerm2 has and how we can combine this with Vim. Recently I wrote about using vim-plug to easily install vim plugins. Using vim-plug I installed the theme “onehalfdark” (Theme link):# .vimrc&quot;# Custom VIM File for CABenstein&quot;## Loading the plugins using vim-plugcall plug#begin()Plug &#39;tpope/vim-sensible&#39;Plug &#39;sonph/onehalf&#39;, { &#39;rtp&#39;: &#39;vim&#39; }Plug &#39;itchyny/lightline.vim&#39;call plug#end()&quot;## Themecolorscheme onehalfdarklet g:airline_theme=&#39;onehalfdark&#39;Now, this is a great basis theme but it uses a custom background color which does not match the color of my iTerm using “Solarized”:Notice the blue bar around the edges? Let’s take care of this.Automatic profile switchingiTerm2 has some amazing features. If you’re running a Mac check it out! I will use the the automatic switching that is enabled by installing the shell integrations. Read the docs over at https://iterm2.com/documentation-automatic-profile-switching.html .Creating a profileI’m gonna create a custom profile called “VIM” and set the background color to the same color used by onehalfdark. That’s 48,48,48:Auto switchingNow, remember, for this part the shell integrations will need to be installed. We will add a auto-switch condition on the Advanced tab. Hint: These settings seem to be applied when you closed the preferences screen. So, if you’re testing keep this in mind.To switch create the trigger &amp;amp;Vim (the capital is important!!!):Now, when you enter Vim you should see the switching taking place:And that’s it! To be honest I googled my way up and down because I was not able to get this to work! The issue in the end was that I was using the trigger &amp;amp;vim instead of &amp;amp;Vim. I really hope someone out there that runs in to the same issue will find this post!" }, { "title": "Pod Affinity and Anti-affinity - Spreading out workloads", "url": "/posts/pod-affinity-and-anti-affinity/", "categories": "EX280", "tags": "openshift, kubernetes, ex280", "date": "2022-02-06 00:00:00 +0100", "snippet": "I have written about using Taints and Tolerations to prevent pods from running on certain (tainted) nodes and there is some influence on scheduling that we can exert using Limits and Requests. But if we really want to control pod placement we have to look no further than Node/Pod Affinity and Anti-Affinity. This allows you to specify nodes that your pod can run on (Pod Affinity) and can be used to spread out your pods at runtime to different nodes using Anti-Affinity. Why? Because it’s great to have a container cluster, but if all your pods are landing on a single note your not gonna have a great (up)time. Let’s get started!As always, these concepts apply to both Kubernetes and Openshift. We will try to do everything from the oc command line.Understanding AffinityAffinity means to have a natural liking to something. In Openshift it means that there is a connection (a preferred grouping) of resources. Naturally Anti-Affinity inverses this. With Affinity you can group workloads together on a single host or ensure that pods land on the same server. This can be useful if your workload gains performance by being scheduled together. The inverse is also true. By using Anti-Affinity rules we can make sure not all of our frontend pods are being run on the same node so that when it might go down or get busy our application pods won’t go down all at once.Affinity is specified in your pod spec, pod.spec.affinity. Tip! Use oc explain pod.spec.affinity for some helpful info:$ oc explain pod.spec.affinityKIND: PodVERSION: v1RESOURCE: affinity &amp;lt;Object&amp;gt;DESCRIPTION: If specified, the pod&#39;s scheduling constraints Affinity is a group of affinity scheduling rules.FIELDS: nodeAffinity &amp;lt;Object&amp;gt; Describes node affinity scheduling rules for the pod. podAffinity &amp;lt;Object&amp;gt; Describes pod affinity scheduling rules (e.g. co-locate this pod in the same node, zone, etc. as some other pod(s)). podAntiAffinity &amp;lt;Object&amp;gt; Describes pod anti-affinity scheduling rules (e.g. avoid putting this pod in the same node, zone, etc. as some other pod(s)).Node AffinityWith nodeAffinity we can ask the pod to be scheduled (or not to be scheduled) on a node with a certain label. This works a lot like a toleration (pod.spec.tolerations)Pod Affinity podAffinity is used to tell our pod to schedule our pod with other pods based on affinity rules podAntiAffinity enables us to separate pods based on affinity rulesRequired fielsWhen using a Affinity rule you also need to specify the topologyKey: kubernetes.io/hostname in the yaml. Also, when using a Preferred rule you need to set a weight so that the scheduler knows (on a scale from 1-100) how strongly it should weigh the preference.Why not taint?At this point you might be asking, why not use a toleration or the nodeSelector found in the pods spec? This is a good question. Using these techniques gives us controll on where to place a pod but it does based on static information on the node. Using Affinity rules we can schedule dynamilcy based on where other pods are located.Affinity RulesSo, how does this work? Affinity Rules use matchExpressions based on key=value pairs to match. We will take the following yaml as an example:kind: Podmetadata: name: looking-for-a-green-podspec: affinity: podAffinity: requiredDuringSchedulingIgnoredDuringExecution: - labelSelector: matchExpressions: - key: color operator: In values: - green - darkgreen - lightgreen topologyKey: kubernetes.io/hostname containers: - name: looking-for-a-green-pod image: docker.io/ocpqe/hello-podThis will create a pod called looking-for-a-green-pod that looks for another pod that has the key color with one of three values green, darkgreen and lightgreen.We could easily create a pod called black-and-white that just wont schedule on the same node as a pod with color defined using the following affinity rule:spec: affinity: podAffinity: requiredDuringSchedulingIgnoredDuringExecution: labelSelector: - matchExpressions: - key: color operator: ExistsUnderstanding operatorsThe operators we can use are: In Meaning one of the values in the key matches our value NotIn Meaning the value is not in the value of the key Exists Meaning the value exists in the key DoesNotExist The value should not exist in the key Lt Lesser then Gt Greater thenRequired and PreferredWe can set up our Affinity rules in two modes, “Required” and “Preferred”. Let me explain: Required Affinity rules have to be met before a pod is scheduled on a node Preferred Affinity rules are, well, preferred. We would like these rules to be met but we can be a bit more flexibleCreating pods with Affinity rulesLets spin up two pods that want to be scheduled together, green-pod and looking-for-a-green-pod:# green-pod.yamlapiVersion: v1kind: Podmetadata: name: green-pod labels: color: greenspec: containers: - name: green-pod image: docker.io/ocpqe/hello-pod# looking-for-a-green-podapiVersion: v1kind: Podmetadata: name: looking-for-a-green-podspec: affinity: podAffinity: requiredDuringSchedulingIgnoredDuringExecution: - labelSelector: matchExpressions: - key: color operator: In values: - green - darkgreen - lightgreen topologyKey: kubernetes.io/hostname containers: - name: looking-for-a-green-pod image: docker.io/ocpqe/hello-podYou can save both these definitions to a yaml file and use oc apply -f FILE to create the. When this is done they should both be running on the same node:$ oc get pods -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATESgreen-pod 1/1 Running 0 11m 10.217.0.98 crc-ktfxm-master-0 &amp;lt;none&amp;gt; &amp;lt;none&amp;gt;looking-for-a-green-pod 1/1 Running 0 64s 10.217.0.101 crc-ktfxm-master-0 &amp;lt;none&amp;gt; &amp;lt;none&amp;gt;Let’s create our pod that does not like any color:# black-and-white.yamlapiVersion: v1kind: Podmetadata: name: black-and-whitespec: affinity: podAntiAffinity: requiredDuringSchedulingIgnoredDuringExecution: - labelSelector: matchExpressions: - key: color operator: Exists topologyKey: kubernetes.io/hostname containers: - name: black-and-white image: docker.io/ocpqe/hello-podNow when we have a look at our pods we will see that our newest one does not like to run with the other pods:$ oc get pods -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATESblack-and-white 0/1 Pending 0 14s &amp;lt;none&amp;gt; &amp;lt;none&amp;gt; &amp;lt;none&amp;gt; &amp;lt;none&amp;gt;green-pod 1/1 Running 0 16m 10.217.0.98 crc-ktfxm-master-0 &amp;lt;none&amp;gt; &amp;lt;none&amp;gt;looking-for-a-green-pod 1/1 Running 0 6m34s 10.217.0.101 crc-ktfxm-master-0 &amp;lt;none&amp;gt; &amp;lt;none&amp;gt; Note Because this is running on CRC which is single node cluster the pod will not start because there are no other nodes available.And we can see the effect with oc describe:$ oc describe pod black-and-white....Events: Type Reason Age From Message ---- ------ ---- ---- ------- Warning FailedScheduling 36s (x2 over 101s) default-scheduler 0/1 nodes are available: 1 node(s) didn&#39;t match pod anti-affinity rules.Not lets change the pod from requiring the affinity rule from being met to a preffered rule. This is not as simple as swapping out requiredDuringSchedulingIgnoredDuringExecution because a preferred rules needs some extra information to work with, we will update our yaml to:apiVersion: v1kind: Podmetadata: name: black-and-whitespec: affinity: podAffinity: preferredDuringSchedulingIgnoredDuringExecution: - weight: 50 podAffinityTerm: labelSelector: matchExpressions: - key: color operator: Exists topologyKey: kubernetes.io/hostname containers: - name: black-and-white image: docker.io/ocpqe/hello-podAs we can see in the events now all pods are scheduled on the same node. Even the black-and-white pod because despite its preference there is simply no other node to run on.$ oc get eventsLAST SEEN TYPE REASON OBJECT MESSAGE1m Normal Scheduled pod/black-and-white Successfully assigned all-together-now/black-and-white to crc-ktfxm-master-0 Wrapping upUsing Affinity Rules can help us dynamically select where our pods are scheduled based on node labels and other pods. This makes it easy to spread out a workload across a cluster or keep pods together for maximum performance.I hope this post has helped you. Check out my other EX280 related content on my EX280 page" }, { "title": "Quotas, limits and limit-ranges", "url": "/posts/quotas-limits-and-limit-ranges/", "categories": "EX280", "tags": "openshift, kubernetes, ex280", "date": "2022-01-29 00:00:00 +0100", "snippet": "In this post we will be diving in to quotas and limits. Quotas and limits can be used to allocate, limit en reserve resources within your cluster for one or multiple namepaces and can limit the usage of CPU and Memory for workloads. Limits can also be used to gurante (by reserving) resources for your workloads.Understanding and using quotas and limits from day one can help plan the resource growth of your cluster and prevents unwanted resource depletion. Using these API objects helps your cluster to more effectively schedule workloads across your cluster while also making sure they get their piece of resources when they need it.As always, these concepts apply to both Kubernetes and Openshift. We will try to do everything from the oc command line.Controlling resources allocationWe have options to control how many resources namespaces and pods are allowed to use or create in a cluster. This comes in handy to prevent unwanted growth of a namespace and prevent depletion of vital compute resources. Let’s start with a overview: Limits (api: can set the limits and request of a workload. With a limit we can limit a workload to use a maximum amount of CPU or request a minimum amount of CPU. You can find limits under pods.spec.containers.resource Limit is the maximum amount of a resource that can be used. Found under pods.spec.containers.resource.limits Request is the amount of a resource that is reserved. Requests are set under pods.spec.containers.resource.requests Limit Ranges are great because they assign default limits and requests to pods that don’t have any and can set a threshold on how much every individual pod can use. This gives you finer control on resource allocation then a Quota because a quota looks at all requests in a namespace. Limit ranges use the API object limitrange Quotas are used to set how many resources a namespace can create and/or request. We can limit the amount of pods that can run in a single namespace. We can also use a quota to limit the amount of CPU all workloads can use by enforcing the usage of a CPU limit on each pod or the amount of memory the workloads can request. A quota is created of the type resourcequota Cluster Quotas can be used across the Openshift cluster and are not bound to a single namespace. A Cluster Qouta of the object clusterresourcequotaWhat do the units mean?When we request or limit compute resources we do this on Memory and CPU . The amount that we want is expressed in units in different ways in yaml: CPU A single virtual CPU is always a 1 in yaml or 1000m. We can use the smaller unit to divide and share the CPU computing power between workloads. The actual clock speed of the CPU in this case is not relevant but could have an impact when you move to another cluster or CPU type 1. Memory Unlike CPU memory is expressed in bytes. You can use a fixed number like 1500M or a power-of-two equivalent like 512Mi [^MemoryInKubernetes]. We will use the later in our examples.Understanding LimitsA limit can consist of an upper value (limit) and lower (request) threshold that you set on a pod or container. Limits on individual pods are usually baked in to the yaml by most applications (you’ll see a lot of cpu: 10m requests in containers, see below for why). Most of the time we will set a limit for a complete deployment.Limits on a pod can look like this on a deployment:apiVersion: apps/v1kind: Deploymentmetadata:....spec:.... spec: containers: .... resources: limits: cpu: 500m memory: 512Mi requests: cpu: 10m memory: 128Mi The request partA part of a limit is that you can also set a request. This tells the scheduler that in order to run your workload you’ll need a certain amount of CPU or Memory. The scheduler will place your pods on a node that has this amount free and the amount you request is held in reserver for you. A lot of pods have a CPU request of 10m. So thats 1/100 of a vCPU. The reason for this is that they often don’t use a lot of CPU but in the case of a high load on a node they would still receive some CPU from the node. Some things to keep in mind: If you set no requests on a pod and the node on which the pod is running is getting busy your pod might not receive any CPU or Memory. Why? Because you didn’t tell the cluster you needed any If you set only a limit and no request of a resource type the cluster will take your limit and turn it in to the request. So if you set a high limit, be sure to set the right request so that your pod wont eat up all resources 2. If you set a request but no limit the cluster will try to default to the values set in a limitrange or the cluster default setting 3.Hitting a limitSo we set a limit. Everything is running but then al of sudden cHaOs. Pods go wild, workloads go crazy! Your whole namespace is on fire! 🔥 Resources are being eaten up by different pods. CPU and memory usage is climbing! What will happen now? Hitting the CPU Limit No worries, hitting a CPU limit is not cause for panic. Your pods will be throttled by the cluster. This might have some unforseen impact on perfomance but in most cases your fine Hitting the Memory Limit Now this is a bit more tricky. When you hit your memory limit in a cluster the cluster will kill the workout with the classic line OOM (Out Of Memory). Even if the node has 48Gi of Memory and is not using half of it. If your pod hits your defined Memory limit it is killed 4.Understanding Limit RangesA limit applies a limit (or request) of resources on a pod. A limitrange can apply a minimum, maximum or default value for limits and requests of a pod or container in your namespace. If for example you want to have all pods in a namespace request a minimum of 128Mi of Memory you can create a limitrange to do this.Limits on a whole NamespacesAs we said before. We set limits on pods (using the deployment) or on individual containers. But how do we control the total usage of CPU and Memory of a namespaces? But how do we do this? By using a quota!Understanding QuotasQuotas can be used to limit the amount of resources that can be created, requested or used. Usually quotas are set on a namespace basis (so they apply to the sum of the resources in the namespace) but they can also be set on a group of namespaces or even on a per user basis.Limits can for example: Control the maximum amount of pods that can run Limit the amount of routes used by a namespace Control how many services can be created Set the maximum amount of CPU all pods can request Set a maximum amount of Memory that can be used at onceIn short “Quotas can be used to apply limits”.A quota can look like thisapiVersion: v1kind: ResourceQuotametadata: name: my-quota namespace: a-quota-for-mespec: hard: cpu: &quot;1&quot; memory: 1G persistentvolumeclaims: &quot;10&quot; pods: &quot;2&quot; replicationcontrollers: &quot;2&quot; resourcequotas: &quot;1&quot; secrets: &quot;5&quot; services: &quot;3&quot;cpu and memory in this example relate to requests. To set a limit use limits.cpu and limits.memory. You can also go 100% correct and use requests.cpu and requests.memory and save yourself some troubleshooting time in the future.Understanding quota rangesA quota can be crated with two different scopes: resourcequota Is created with oc create quota clusterresourcequota Is created with oc create clusterresourcequotaSo what are the differences?Range of resourcequotaA quota of the type resourcequota is designed to apply a quota of resources to one project or namespace. You could add this resource to the default template of your Openshift projects creation to apply a default quota to all new projects that are created.The quota is created on a project/namespace level.Range of clusterresourcequotaAs the name suggets, cluster quotas (clusterresourcequota) are created and designed to work across you cluster. The way they are applied is by using selectors that matches to a label on a project or by using the openshift.io/requester annotation to link them to a project owner. This can come in handy when you are also using the cluster for developers to experiment on and don’t want them to eat up all the resources. Be sure to update the openshift.io/requester value on other projects.Cumulative QuotasYou can create (or apply) multible quota’s to a single namespace (but this is not recomendend). If you do, the effect is cummulative (meaning all quota’s will be merged in to one). If you specify the quota for a specifiek resourcetype (like pods) in multible quota’s the lowest value will be used. For example:$ oc get resourcequotasNAME AGE REQUEST LIMITquota-1 3m pods: 5/10, secrets: 9/10quota-2 3m configmaps: 2/10, pods: 5/52 Quota’s are set: quota-1 and quota-2. One specifies a limit on secrets and the other on configmaps. This is added up, you an create 10 configmaps and secrets.Both quota’s specify a maximum number of running pods (max: 5 and max: 10). The lowest one takes precedence. So a maximum of 5 pods can run.Failure due to quotasWhen you set a quota and you try to start things up that exceed that quota some strange things might happen, like: When you set a quota of 1 pod per namespace and you try to do a rolling deployment you might encounter some issues. This is because for a rolling deployment to work two (or more depending on the amount of replicas) are required. This is not allowed by your quota so it will get stuck If you try to start up a pod with no requests or limits but you have set resource limits in your quota the pods will not start (because it has no limits set) When exceeding the amount of Memory that is allowed by your quota Openshift will give you some time to adjust in stead of killing your pod.Creating and viewing Limits and RequestsLets get bussy on the command line and create some limits and requestLimits on PodsLets create a namespace called limit-the-sky with a demo app called airplane:$ oc new-project limit-the-sky$ oc new-app --name airplane --image bitnami/nginxNow lets do something crazy. Let’s set a request thats way to high for our current cluster:$ oc set resources deployment airplane \\ --requests cpu=12deployment.apps/airplane resource requirements updatedWhat did we do? We set a request for our app for 12 whole vCPU’s. Let’s see if that flies:$ oc get podsNAME READY STATUS RESTARTS AGEairplane-5d8d87c8d5-lsqsd 0/1 Pending 0 58sairplane-779789c8cc-2sfqz 1/1 Running 0 2m32s $ oc describe pod airplane-5d8d87c8d5-lsqsd....Events: Type Reason Age From Message ---- ------ ---- ---- ------- Warning FailedScheduling 24s (x2 over 91s) default-scheduler 0/1 nodes are available: 1 Insufficient cpu.As we can see that just won’t fly in the current cluster. Now lets set something more realistlcy. We are going to ask our cluster for 10m CPU and 128Mi of memory and we are going to set a upper limit of a half vCPU (500m or 0.5) and a maximum amount of Memory of 512Mi:$ oc set resources deployment airplane \\ --requests cpu=10m,memory=128Mi \\ --limits cpu=500m,memory=512Mideployment.apps/airplane resource requirements updated That flies:$ oc get podsNAME READY STATUS RESTARTS AGEairplane-59cbf468f7-w52xq 1/1 Running 0 18s We can always check the limit of a deployment using the oc describe command:$ oc describe deployment airplane .... Pod Template: Labels: deployment=airplane Annotations: openshift.io/generated-by: OpenShiftNewApp Containers: airplane: Image: bitnami/nginx@sha256:78cb209a82fca83aee2f2d71f7115165f911acf1fcc6ce48e1c8bddeb5191049 Ports: 8080/TCP, 8443/TCP Host Ports: 0/TCP, 0/TCP Limits: cpu: 500m memory: 512Mi Requests: cpu: 10m memory: 128Mi Environment: &amp;lt;none&amp;gt; Mounts: &amp;lt;none&amp;gt; Volumes: &amp;lt;none&amp;gt;Setting default, min and max with a limitrangeNow, you don’t want to manually add limits and requests to everything. We can take care of this by creating a limitrange. A limitrange can’t entirly be created from CLI but the setup is pretty easy (tip: use oc explain limitrange to see the available fields):# limit-range.yamlapiVersion: v1kind: LimitRangemetadata: name: a-limit-range namespace: limit-the-skyspec: limits: - type: Container default: cpu: 50m max: cpu: 500m min: cpu: 10m$ oc apply -f limit-range.yamllimitrange/a-limit-range createdAnd let’s have a look at it:$ oc describe limitranges a-limit-rangeName: a-limit-rangeNamespace: limit-the-skyType Resource Min Max Default Request Default Limit Max Limit/Request Ratio---- -------- --- --- --------------- ------------- -----------------------Container cpu 10m 500m 50m 50mAnd now, when we crate a new deployment that has no CPU limits:$ oc new-app --name zeplin --image bitnami/nginxAnd let’s have a look:$ oc get pods zeplin-b79b4dcf6-jgtkh -o yaml | grep cpu kubernetes.io/limit-ranger: &#39;LimitRanger plugin set: cpu request for container zeplin; cpu limit for container zeplin&#39; cpu: 50m cpu: 50m What happens if we try to go above (or below) the limit?$ oc set resources deployment/zeplin --limits cpu=1000mdeployment.apps/zeplin resource requirements updatedThat’s strange? We set the mac allowed CPU to 500m right? So, why no error? So, there is actually an error but it’s hard to find. You can see the error using oc get events , by doing a oc get replicasets or by using oc describe deployment zeplin. You will see that the cluster is refusing to rollout the latest replicaset because of the limitrange:$ oc get events | grep cpu....7m33s Warning FailedCreate replicaset/zeplin-7dc7446698 Error creating: pods &quot;zeplin-7dc7446698-cpqdh&quot; is forbidden: maximum cpu usage per Container is 500m, but limit is 1k7m32s Warning FailedCreate replicaset/zeplin-7dc7446698 Error creating: pods &quot;zeplin-7dc7446698-cdxdm&quot; is forbidden: maximum cpu usage per Container is 500m, but limit is 1k6m11s Warning FailedCreate replicaset/zeplin-7dc7446698 (combined from similar events): Error creating: pods &quot;zeplin-7dc7446698-95g7s&quot; is forbidden: maximum cpu usage per Container is 500m, but limit is 1kOr in the deployment:$ oc describe deployment zeplin....Conditions: Type Status Reason ---- ------ ------ ReplicaFailure True FailedCreate Available True MinimumReplicasAvailable Progressing True ReplicaSetUpdatedOldReplicaSets: zeplin-b79b4dcf6 (1/1 replicas created)NewReplicaSet: zeplin-6f58fb66cd (0/1 replicas created)Creating and viewing QuotasNow lets take a step back and look at a the bigger picture. It’s great to set limits and requests on pods but this is a cluster we are using. So lets step it up. We are going to create a namespace a-quota-for-me with a our quota called my-quota:$ oc new-project a-quota-for-me$ oc create quota my-quota \\ --hard=cpu=1,memory=1G,pods=2,secrets=1resourcequota/my-quota createdLet’s have a look at our quota:$ oc describe resourcequotas my-quotaName: my-quotaNamespace: a-quota-for-meResource Used Hard-------- ---- ----cpu 0 1memory 0 1Gpods 0 2secrets 9 1Thats strange! 9 secrets in use? But we set a limit to 1? This can happen because we set the quota after the creation of these secrets. A quota enforces its restrictions on new resources and not on existing. For example, when we try to create a secret now:$ oc create secret generic just-try-it --from-literal key1=passworderror: failed to create secret secrets &quot;just-try-it&quot; is forbidden: exceeded quota: my-quota, requested: secrets=1, used: secrets=9, limited: secrets=1 Applying quota to a deploymentNow lets run a demo application called you-can-quota-me-on-that:$ oc new-app \\ --name you-can-quota-me-on-that \\ --image bitnami/nginx \\ --as-deployment-configBut our pod is nowhere to be found:$ oc get podsNo resources found in a-quota-for-me namespaceWhy? Because we set a resource limit in the quota (a CPU and Memory max) and our pod does not have one:$ oc describe deploymentconfigs you-can-quota-me-on-that .... Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal DeploymentCreated 4m20s deploymentconfig-controller Created new replication controller &quot;you-can-quota-me-on-that-1&quot; for version 1 Warning FailedRetry 2m42s deployer-controller Stop retrying: couldn&#39;t create deployer pod for &quot;a-quota-for-me/you-can-quota-me-on-that-1&quot;: pods &quot;you-can-quota-me-on-that-1-deploy&quot; is forbidden: failed quota: my-quota: must specify cpu,memory Warning FailedCreate 95s (x24 over 4m20s) deployer-controller Error creating deployer pod: pods &quot;you-can-quota-me-on-that-1-deploy&quot; is forbidden: failed quota: my-quota: must specify cpu,memoryOr:$ oc get events61s Warning FailedCreate deploymentconfig/you-can-quota-me-on-that Error creating deployer pod: pods &quot;you-can-quota-me-on-that-1-deploy&quot; is forbidden: failed quota: my-quota: must specify cpu,memorySo lets set a request like in our previous example:$ oc set resources deploymentconfig you-can-quota-me-on-that \\ --requests cpu=10m,memory=56Mideploymentconfig.apps.openshift.io/you-can-quota-me-on-that resource requirements updatedBut that won’t do the trick. Why? Because we set the requests on the pod and the error message is telling us the deployer pod is no allowed. So lets edit that by hand. To do that we add the requests under the deployment strategy:$ oc edit deploymentconfigs you-can-quota-me-on-thatspec: replicas: 1 revisionHistoryLimit: 10 selector: deploymentconfig: you-can-quota-me-on-that strategy: activeDeadlineSeconds: 21600 resources: {} rollingParams: intervalSeconds: 1 maxSurge: 25% maxUnavailable: 25% timeoutSeconds: 600 updatePeriodSeconds: 1 type: Rolling resources: requests: cpu: 10m memory: 56MiNow lets rollout the latest version:$ oc rollout latest you-can-quota-me-on-thatdeploymentconfig.apps.openshift.io/you-can-quota-me-on-that rolled outNAME READY STATUS RESTARTS AGEyou-can-quota-me-on-that-3-deploy 0/1 Completed 0 24syou-can-quota-me-on-that-3-k2pl7 1/1 Running 0 18sHitting quota limitsLet’s scale that up to 4 replicas:$ oc scale deploymentconfig you-can-quota-me-on-that --replicas 4deploymentconfig.apps.openshift.io/you-can-quota-me-on-that scaled$ oc get podsNAME READY STATUS RESTARTS AGEyou-can-quota-me-on-that-3-deploy 0/1 Completed 0 70syou-can-quota-me-on-that-3-k2pl7 1/1 Running 0 64syou-can-quota-me-on-that-3-v5xnp 1/1 Running 0 10s That’s stange. Where are the pods? As mentioned before. A quota denies deployment of resources that exceed the quota. We have requested four pods to be created but the cluster will only give use two.We can see the error in the replicationcontroller$ oc describe replicationcontrollers you-can-quota-me-on-that-3....Events: Type Reason Age From Message ---- ------ ---- ---- ------- Warning FailedCreate 2m35s replication-controller Error creating: pods &quot;you-can-quota-me-on-that-3-tcn57&quot; is forbidden: exceeded quota: my-quota, requested: pods=1, used: pods=2, limited: pods=2 Warning FailedCreate 2m35s replication-controller Error creating: pods &quot;you-can-quota-me-on-that-3-w9wp6&quot; is forbidden: exceeded quota: my-quota, requested: pods=1, used: pods=2, limited: pods=2 Warning FailedCreate 25s (x8 over 2m34s) replication-controller (combined from similar events): Error creating: pods &quot;you-can-quota-me-on-that-3-zmp82&quot; is forbidden: exceeded quota: my-quota, requested: pods=1, used: pods=2,Creating a clusterresourcequotaWe can create a cluster quota that wil target our user anna with the following command5:$ oc create clusterquota for-user-anna \\ --project-annotation-selector openshift.io/requester=anna \\ --hard pods=10 \\ --hard secrets=20 To see a resourcequota that is applied to the namespace use:$ oc describe AppliedClusterResourceQuotaName: for-user-annaCreated: 2 minutes agoLabels: &amp;lt;none&amp;gt;Annotations: &amp;lt;none&amp;gt;Namespace Selector: [&quot;annas-project&quot;]Label Selector:AnnotationSelector: map[openshift.io/requester:anna]Resource Used Hard-------- ---- ----pods 10 10secrets 9 20 Wrapping it upThis post turned out rather long! Lets review the information with some examples: We use Limits to set a limit (the maximum amount of a resource that a pod can use) and requests (the amount of resources a pod needs and is ensured) on containers and pods. You can use a limit to set the maximum amount of CPU usage by a pod or container to 1 CPU You can ensure a pod or container always gets 512Mi of Memory using a request We use LimitRanges to set a default, minimum or maximum of the resources each pod can get. We can use a LimitRange to set a default Memory request for all pods A LimitRange can limit the maximum amount of CPU a pod can request to 200m We use ResourceQuota to set the maximum number of objects in a namespace or to enforce the usage of a limit and the total amount of resources a namespace can use A quota in a namespace can limit the sum of all CPU requests to 2 CPU’s (2000m or 2) You can limit the amount of routes you can have in a namespace to 1 You can force pod’s to have a set limit or request And we can use a ClusterResourceQuota to span a quota over multiple namespaces based on a field tag or the requester (owner) of a project. With a cluster quota we can set a limit of 20 pods that can be running by a user We can limit the amount of CPU used to 4 (4000m) of several namespaces that we have tagd as production=true All in all, pretty usefull stuf. Be sure to practice with this and run in to strange situations!Do you want to see more of my EX280 post’s? Checkout my EX280 page https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#meaning-of-cpu &amp;#8617; https://kubernetes.io/docs/tasks/administer-cluster/manage-resources/cpu-default-namespace/#what-if-you-specify-a-container-s-limit-but-not-its-request &amp;#8617; https://kubernetes.io/docs/tasks/administer-cluster/manage-resources/cpu-default-namespace/#what-if-you-specify-a-container-s-request-but-not-its-limit &amp;#8617; https://kubernetes.io/docs/tasks/configure-pod-container/assign-memory-resource/#if-you-do-not-specify-a-memory-limit &amp;#8617; https://docs.openshift.com/container-platform/4.8/applications/quotas/quotas-setting-across-multiple-projects.html &amp;#8617; " }, { "title": "Scaling applications - Rollout, Scale and Auto-Scale Deployments", "url": "/posts/controlling-pod-rollout-and-scaling/", "categories": "EX280", "tags": "openshift, kubernetes, ex280", "date": "2022-01-23 00:00:00 +0100", "snippet": "This post is gonna be a bit bigger broader then what is requested on the EX280 exam objectives. In this post we will have a look at: Controlling roll-out of pods (manually rolling out or back a deployment) Scaling Deployments on the command-line Creating a auto scaler for a deployment on the command-lineNow, apart from the scaling being an exam objective it’s really handy to know how to scale pods and how to control the rollout of deployments. This is certainly something I use almost on a daily basis when operating a container cluster. So, let’s go!What even is a “Deployment”When we use oc new-app we are creating a Deployment that sets up a ReplicaSet which in turn starts te pods.graph LR Deployment --&amp;gt; |Manages| ReplicaSet--&amp;gt; |Manages| PodsLet’s have a look at the options.Deployment or DeploymentConfigSo, I found this really confusing. In Openshift there are resource to control your deployment (the app that you want to run). In short, this is how it is: Deployment is an API resource that controls ScaleSets and Pods. The deployment resource is kubernetes native and is the default that is being used when using oc new-app 1 DeplymentConfig is almost the same as a deployment. It used to be included in Kubernetes but has been removed from the API. In Openshift we can still use the resource when we use the oc new-app command with the flag --as-deployment-config 1To create a DeploymentConfig from the command line use:$ oc new-app --as-deployment-config ... Deployment and DeploymentConfigs are API object in your cluster that manage the pods that are running. They do this (most of the time) by using ScaleSets. When u update a Deployment (with a ConfigMap for example) the Deployment will trigger a new rollout of the pod(s).Viewing Deployments and DeploymentConfigsWe can view Deployments and DeploymentConfigs with the basic oc get RESOURCE_TYPE command. To get some data we will setup a namespace and deploy two app’s to it. We will create the app deployment-app as an example of a Deployment and a second app called deploymentconfig-app as an example of a DeploymentConfig:$ oc new-project deploying-can-be-fun$ oc new-app --name deployment-app --image bitnami/nginx$ oc new-app --as-deployment-config --name deploymentconfig-app --image bitnami/nginxNow lets get them:$ oc get deploymentNAME READY UP-TO-DATE AVAILABLE AGEdeployment-app 1/1 1 1 51$ oc get deploymentconfigAME REVISION DESIRED CURRENT TRIGGERED BYdeploymentconfig-app 1 1 1 config,image(deploymentconfig-app:latest)Straight away we can see a difference between the two. The “Triggered by” field is shown on the the DeploymentConfig. As we can see the app will be rolled out when the config changes and it’s currently on the latest statusRolling out a new DeploymentWhat if you want to rollout a new version of your app? Just for fun without changing it. We can do thatDeploymentConfig styleRunning a new deployment with a DeploymentConfig is really easy, use 2 :$ oc rollout latest deploymentconfig/deploymentconfig-appdeploymentconfig.apps.openshift.io/deploymentconfig-app rolled outAnd your done. To verify your work you can use oc rollout history to see that the cluster has rolled out a new version:$ oc rollout history deploymentconfig/deploymentconfig-appdeploymentconfig.apps.openshift.io/deploymentconfig-appREVISION STATUS CAUSE1 Complete config change2 Complete manual change Deployment styleTo trigger a new rollout of a Deployment we are going to change something in the Deployment. We will trigger a new rollout by updating the “last restart” of the container using oc patch:$ oc patch deployment/deployment-app --patch \\&quot;{\\&quot;spec\\&quot;:{\\&quot;template\\&quot;:{\\&quot;metadata\\&quot;:{\\&quot;annotations\\&quot;:{\\&quot;last-restart\\&quot;:\\&quot;`date +&#39;%s&#39;`\\&quot;}}}}}&quot;deployment.apps/deployment-app patchedRolling backA great feature of rollouts is that a history of your rollouts is kept. This makes it easy to recover from configuration mistakes or to abort and rollback the release of a new rollout.To rollback a rollout you can use oc rollout undo:$ oc rollout undo deploymentconfig deploymentconfig-appdeploymentconfig.apps.openshift.io/deploymentconfig-app rolled back $ oc rollout undo deployment deployment-appdeployment.apps/deployment-app rolled back Deployment historyAs seen in a previous example we can see the history of rollouts. This also gives us the ability to rollback to a specific version, simply use the --to-revision flag:$ oc rollout history deploymentconfig/deploymentconfig-appdeploymentconfig.apps.openshift.io/deploymentconfig-appREVISION STATUS CAUSE1 Complete config change2 Complete manual change3 Complete manual change$ oc rollout undo --to-revision 1 deploymentconfig/deploymentconfig-appdeploymentconfig.apps.openshift.io/deploymentconfig-app rolled backFurther optionsThere are allot of other options you can use with oc rollout. Have a look at the help prompt:$ oc rollout -hStart a new rollout, view its status or history, rollback to a previous revision of your app.....Usage: oc rollout SUBCOMMAND [flags]Available Commands: cancel Cancel the in-progress deployment history View rollout history latest Start a new rollout for a deployment config with the latest state from its triggers pause Mark the provided resource as paused restart Restart a resource resume Resume a paused resource retry Retry the latest failed rollout status Show the status of the rollout undo Undo a previous rollout Scaling it upOne thing that you hear allot when talking about container platforms is the ability to “scale up” applications. This is done by increasing the number of pods that run you application. Scaling can be done manually or automatically by your cluster. Let’s have a look.Scaling from the command lineWe will use a demo app called scale-me for this demo in the namespace the-sky-is-the-limit:$ oc new-project the-sky-is-the-limit$ oc new-app --name scale-me --image bitnami/nginxWhen we take a look at the running pods we will see that our new-app command created a single pod:$ oc get podsNAME READY STATUS RESTARTS AGEscale-me-85b69877f9-xxvbp 1/1 Running 0 92sLet’s scale it up using the oc scale command:$ oc scale deployment/scale-me --replicas 10deployment.apps/scale-me scaled$ oc get podsNAME READY STATUS RESTARTS AGEscale-me-85b69877f9-czjvm 1/1 Running 0 13sscale-me-85b69877f9-jdcwp 1/1 Running 0 13sscale-me-85b69877f9-k6v45 1/1 Running 0 13sscale-me-85b69877f9-k75c4 1/1 Running 0 13sscale-me-85b69877f9-ldsv4 1/1 Running 0 13sscale-me-85b69877f9-p2pq2 1/1 Running 0 13sscale-me-85b69877f9-pspnn 1/1 Running 0 13sscale-me-85b69877f9-sl78f 1/1 Running 0 13sscale-me-85b69877f9-t62b8 1/1 Running 0 13sscale-me-85b69877f9-xxvbp 1/1 Running 0 2m24sAnd well, that’s it. It’s that easy.Scaling on autoAs I wrote before. Scaling can also be done automatically. Normally this is done by letting the cluster keep an eye on the CPU usage of the pods 3. We do this by creating a autoscaler. An autoscaler can automatically increase or decrease number of pods deployed within the deployment as needed. Info: The autoscaler uses the Openshift metric server to check the CPU usage of a pod. If you do not have a running metric server (like when using CRC) you can create autoscalers but they wont do anythingCreating a auto-scalerTo create the autoscale we will use oc autoscaler. We will set it to scale to minimum of 5 pods and a max of 10. We will use 60% as the target CPU usage:$ oc autoscale deployment/scale-me \\ --min 5 \\ --max 10 \\ --cpu-percent 60horizontalpodautoscaler.autoscaling/scale-me autoscaledAnd thats it… Ow wait! There is more. If you been following along with this last example and you do a oc get pods you might notice something strange:$ oc get podsNAME READY STATUS RESTARTS AGEscale-me-85b69877f9-czjvm 1/1 Running 0 10mscale-me-85b69877f9-jdcwp 1/1 Running 0 10mscale-me-85b69877f9-k6v45 1/1 Running 0 10mscale-me-85b69877f9-k75c4 1/1 Running 0 10mscale-me-85b69877f9-ldsv4 1/1 Running 0 10mscale-me-85b69877f9-p2pq2 1/1 Running 0 10mscale-me-85b69877f9-pspnn 1/1 Running 0 10mscale-me-85b69877f9-sl78f 1/1 Running 0 10mscale-me-85b69877f9-t62b8 1/1 Running 0 10mscale-me-85b69877f9-xxvbp 1/1 Running 0 12m That’s strange? We set the --min to 5 pods right?$ oc get horizontalpodautoscaler.autoscaling/scale-meNAME REFERENCE TARGETS MINPODS MAXPODS REPLICAS AGEscale-me Deployment/scale-me &amp;lt;unknown&amp;gt;/60% 5 10 10 7m38 So why are there still 10 pods running? This is because the autoscale resource uses the requested CPU of a pod to scale. When we take a look at our Deployment:$ oc get deployment/scale-me -o yaml | grep requestWe will see that our deployment has no requested CPU. I haven’t talked about about requests yet but here is a simple way to set one:$ oc set resources deployment/scale-me --requests cpu=200mdeployment.apps/scale-me resource requirements updated After this our pod’s should be rolled out once again (because of a config change) and the cluster should scale them down to 5.Wrapping upI hope you found this useful. I really struggled with the difference between Deployment and DeploymentConfig at the start. Let’s hope this has helped you.Do you want to see more of my EX280 post’s? Checkout my EX280 page https://docs.openshift.com/container-platform/4.9/applications/deployments/what-deployments-are.html &amp;#8617; &amp;#8617;2 https://docs.openshift.com/container-platform/4.9/applications/deployments/managing-deployment-processes.html &amp;#8617; https://docs.openshift.com/container-platform/4.9/nodes/pods/nodes-pods-autoscaling.html &amp;#8617; " }, { "title": "ServiceAccounts and SCCs - Running pods with more permission&#39;s", "url": "/posts/troubelshooting-permissions-on-pods/", "categories": "EX280", "tags": "openshift, kubernetes, ex280", "date": "2022-01-17 00:00:00 +0100", "snippet": "In this blog we will take a look at SCC permissions that are needed to run a pod with escalated permissions and how to use a serviceaccount (sa) to run such a pod or deployment.Small thing: I use the term pod and container in this post but I’m referring to the same idea. In Openshift and Kubernetes we talk about pods being the smallest unit of measurement. Each pod usually runs one container but there are pods that run multiple containers.Understanding RootlessI won’t explain fully why and what rootless means in general but will focus on the parts that are importent to know in a Openshift environment and according to the EX280 exam objectives. If you do wanna go deep on rootless, namespaces and more I highly recommend the following video’s by RedHat: Overview of Rootless Podman: Part 1 - Understanding Root Inside and Outside a Container Overview of Rootless Podman: Part 2 - How User Namespaces Work in Rootless ContainersUIDs and NamespacesSo what are Namespaces? A namespace is a feature of the Linux kernel that allows you to segment resources 1. All things that make up a running system or process are at home in a Namespace. You’ll find Process ID’s (PID) in there as well as mounts and user ID’s (UID).Simply said, a Namespace is a organizational container to partition resources in. Now, your Linux base system has a great way of orchestrating all these different resources based on their unique ID’s and maps process ID’s that are spawned inside a container back to the host system so that the stuff that needs running (the processes that make up the containers) can actually get resources and stay separated from each other.So, when we are talking about container technology and containers being “contained” we are actually talking about this awesome namespace feature.So, what are the risks?There are different risks associated with running containers that default to a root account. The obvious risk is the same as on normal Linux server. Imagine all accounts that are available on a Linux host having root privileges. Now imagine someone gaining access to that system. When you run a pod that defaults to the root account (aka a root container) you’re basically exposing the same risk. You can have all the security of a cluster, but if someone manages to drop a executable in a pod or gain access to it they could do a lot of damage.If you want to go deeper on rootless containers, the risks and how to avoid them, check out this video by Synk.Openshift to the rescue(?)One of the things that Openshift takes care of (in comparison with the out-of-the-box Kubernetes cluster) is that it won’t allow root containers to run by default. This can lead to some issues as some containers need more access to the underling host or special resources or that the images are not setup for rootless usage. For these cases Openshift provides Security Context Constraints to manage elevated rights for pods.SCC’s and SA’sSCC? SA? What do you mean? Let me (try) to explain: SCC: Security Context Constrains. A SCC is used to provide access to a certain resource like: anyuid (which allows the pod to run under any UID), hostaccess (which gives the pod host access) and hostnetwork (which, well I’ll let you guess that one yourself) To see all SCCs that are available in you cluster you can use: $ oc get scc -o name securitycontextconstraints.security.openshift.io/anyuid securitycontextconstraints.security.openshift.io/hostaccess securitycontextconstraints.security.openshift.io/hostmount-anyuid securitycontextconstraints.security.openshift.io/hostnetwork securitycontextconstraints.security.openshift.io/machine-api-termination-handler securitycontextconstraints.security.openshift.io/nonroot securitycontextconstraints.security.openshift.io/privileged securitycontextconstraints.security.openshift.io/restricted (to see more details, use oc get scc) SA: A Service Account is used to run a pod with a special SCC. In Openshift you create Service Accounts and bind them to a deployment to hand out permissions. You can see Running a container with elevated permissionsA great container image to use as an example for this post is the nginx container which is available in both a root a rootless version.For our example we will create two apps based on the two different images. One is the official nginx container image and the second one is the bitnami/nginx rootless version:Creating the deploymentsWe will create a new namespace and two apps:$ oc new-project root-more-or-less$ oc new-app --name root-container --image docker.io/nginx$ oc new-app --name rootless-container --image docker.io/bitnami/nginxStrait away we can see some issues with our root pod:$ oc get podsNAME READY STATUS RESTARTS AGEroot-container-67c49b777d-wdzn5 0/1 Error 3 (28s ago) 58srootless-container-59c496f955-zh7qd 1/1 Running 0 76s TroubleshootingLet’s have a look at whats going on here. We will start with a simple oc status command:$ oc status --suggest....Errors: * pod/root-container-67c49b777d-wdzn5 is crash-loopingThe container is starting and exiting repeatedly. This usually means the container is unable to start, misconfigured, or limited by security restrictions. Check the container logs with oc logs root-container-67c49b777d-wdzn5 -c root-containerCurrent security policy prevents your containers from being run as the root user. Some images may fail expecting to be able to change ownership or permissions on directories. Your admin can grant you access to run containers that need to run as the root user with this command: oc adm policy add-scc-to-user anyuid -n root-or-less -z default....Of the bat we get two hints of fixing this. oc status is telling us to check the logs of the pod and that the pod might not be able to run due to a SCC. Let’s not blindly follow the suggestion of adding anyuid to this pod and explore further with the logs:$ oc logs root-container-67c49b777d-wdzn5/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d//docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh10-listen-on-ipv6-by-default.sh: info: can not modify /etc/nginx/conf.d/default.conf (read-only file system?)/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh/docker-entrypoint.sh: Configuration complete; ready for start up2022/01/22 15:51:47 [warn] 1#1: the &quot;user&quot; directive makes sense only if the master process runs with super-user privileges, ignored in /etc/nginx/nginx.conf:2nginx: [warn] the &quot;user&quot; directive makes sense only if the master process runs with super-user privileges, ignored in /etc/nginx/nginx.conf:22022/01/22 15:51:47 [emerg] 1#1: mkdir() &quot;/var/cache/nginx/client_temp&quot; failed (13: Permission denied)nginx: [emerg] mkdir() &quot;/var/cache/nginx/client_temp&quot; failed (13: Permission denied)As we can see, the pod is expecting to be run as a root user: [warn] 1#1: the &quot;user&quot; directive makes sense only if the master process runs with super-user privileges, ignored in /etc/nginx/nginx.conf:2Before we fix this, let’s check out the SCC’s the pod’s are currently using:$ oc describe pod | grep -i SCC openshift.io/scc: restricted openshift.io/scc: restrictedNow lets use this amazing policy command to find out what SCC our root container wants to user:$ oc get pod root-container-67c49b777d-wdzn5 -o yaml \\ | oc adm policy scc-subject-review -f -RESOURCE ALLOWED BYPod/root-container-67c49b777d-wdzn5 anyuidLooks like our pod wants to use anyuid just as suggested when we ran the oc status command.Creating a ServiceAccountAs mentioned before, if you want to run a pod with a different SCC you’ll need to create a ServiceAccount to run the pod. The SA will provide the runtime with the elevated permissions that we add to the SAWe will create a SA called ok-go-for-it in our namespace with:$ oc create sa ok-go-for-it \\ --namespace root-more-or-less serviceaccount/ok-go-for-it createdA small tip, always create the SA with a --namespace (or -n) flag to ensure the SA is bound to the namespace.Giving special permissions to a ServiceAccountNow let’s add some permissions to our brand spanking new SA. We use oc adm policy to add permissions to users, groups and ServiceAccounts. When we add permissions to a SA we use the -z flag:$ oc adm policy add-scc-to-user -hAdd a security context constraint to users or a service account.Usage: oc adm policy add-scc-to-user SCC (USER | -z SERVICEACCOUNT) [USER ...] [flags $ oc adm policy add-scc-to-user anyuid \\ -z ok-go-for-it \\ --namespace root-more-or-lessclusterrole.rbac.authorization.k8s.io/system:openshift:scc:anyuid added: &quot;ok-go-for-it&quot;Adding a ServiceAccount to a DeploymentNow to update our app. We got our SA ready and our permissions permitted. Let’s not waist time with editing yaml and set the serviceaccount for our app using oc set:$ oc set serviceaccount deployment root-container ok-go-for-itdeployment.apps/root-container serviceaccount updatedAnd just to verify:$ oc get podsNAME READY STATUS RESTARTS AGEroot-container-5d6c7cc66b-sqhhs 1/1 Running 0 19srootless-container-59c496f955-zh7qd 1/1 Running 0 20m $ oc describe pod | grep -i SCC openshift.io/scc: anyuid openshift.io/scc: restrictedWrapping upAs you can see it’s pretty easy to use SAs to apply special permissions to deployments. That doesn’t mean you should do it without thought. There are use cases in which it’s necessary that a deployment might need to run with elevated permissions but there are a lot of other solution’s than simply handing out the permissions. So stay sharp!Do you want to see more of my EX280 post’s? Checkout my EX280 page https://en.wikipedia.org/wiki/Linux_namespaces &amp;#8617; " }, { "title": "Creating and Using Secrets in OpenShift", "url": "/posts/create-and-use-secrets-openshift/", "categories": "EX280", "tags": "openshift, kubernetes, ex280", "date": "2022-01-16 00:00:00 +0100", "snippet": "Creating Secrets (like creating ConfigMaps) is a vital part of Managing OpenShift workloads and is an exam objectives of the EX280 exam. Knowing how they work and how to configure them (from the command-line) will give you a better understanding of Secrets.Secrets, how do they workSecrets provide information (like config files or credentials) to workloads in your cluster. You can use a secret to provide a username and password to your pod or to add a SSL certificate to it.No data on the nodeWhen exposing secrets using volumes the data is stored in a tmpfs filesystem. This means that the data in de secret is not directly exposed to the node that the pod’s are running on1.This provides a bit more security than that of ConfigMaps.Secret typesThere are 3 secret types available for you to us. Don’ worry, they are quite easy to keep apart: docker-registry secrets are used by the internal docker registry of your container platform tls secrets are used to provide tls certificates, keys or other supporting files to a pod generic secrets are used to store everything from an API key to a config fileI will be discussing generic secrets in this post.Encoding vs EncryptionAn important factor to know when working with secrets are that they are not encrypted. The “secret” part of secrets is that they are not readable without decoding them. By default secrets are encodes in a base64 encoding. When you create a secret with, for example, a password key=value pair; the value will be encoded in base64.We can simulate this in bash:$ echo &#39;encoded_password&#39; | base64ZW5jb2RlZF9wYXNzd29yZAo=$ echo &#39;ZW5jb2RlZF9wYXNzd29yZAo=&#39; | base64 -dencoded_passwordIn this case the key=value pair would be rendered in our secret like this (because only the value is encoded, and not the key):password=ZW5jb2RlZF9wYXNzd29yZAo=When we create a secret from yaml we need to encode it first. But when we create a secret with oc create the cluster takes care of this encoding for us. If you would use oc edit to live edit a secret, don’t forget to encode the string you are replacing.Creating a secretCreating a secret can be done by creating a yaml file and applying it to the cluster or by using the oc create secret command.Creating a secret from yamlCreating a secret form a yaml definition is quite easy when you know the layout. You always get an example from the official documentation or use oc explain secretsThe following is a yaml secret with our own value filled in:# our-secret.yamlapiVersion: v1kind: Secretmetadata: name: test-secret namespace: project-of-secretstype: Opaque data: password: ZW5jb2RlZF9wYXNzd29yZAo=If we wanted to create a secret from this we would do so with:$ oc apply -f our-secret.yaml Creating a secret from the cliIf your in a hurry (or don’t want to create yaml files for all your secrets). You can create a secret without a definition file.As a demo you can setup a special testing namespace. As you can see in my yaml example I called this one project-of-secrets:$ oc new-project project-of-secrets From LiteralYou could create a secret from the command-line with the following command:$ oc create secret generic \\ SECRET_NAME \\ --from-literal KEY1=VALUE1 \\ --from-literal KEY2=VALUE2As an example:$ oc create secret generic test-secret-literal \\--from-literal password=encoded_secret secret/test-secret-literal createdFrom FileIf you want your secret to be filled with an entire file:$ oc create secret generic \\ SECRET_NAME \\ --from-file KEY1=/PATH/TO/FILE1 As an example:$ echo &quot;Our verry secret file&quot; &amp;gt; secret-file.txt$ oc create secret generic test-secret-file --from-file secret-file.txtsecret/test-secret-file createdAdding a secret to a podSecrets can be supplied to a pod much like ConfigMaps. For more info on those, I wrote an entire blog regarding the creation and usage of them.Just like ConfigMaps we can provide secret data to pods as ENV variables or as a volume. We will use the secret/test-secret-literal and our demoapp as an example, you can create a demo app with:$ oc new-app --name demoapp --docker-image bitnami/nginx--&amp;gt; Creating resources ... imagestream.image.openshift.io &quot;demoapp&quot; created deployment.apps &quot;demoapp&quot; created service &quot;demoapp&quot; createdSecret as ENV VariableWe use the oc set env command to set a secret as ENV Vars for our pod:$ oc set env deployment/demoapp \\--from secret/test-secret-literaldeployment.extensions/demoapp updated We can now see the secret in action when we enter the pod:$ oc get podsNAME READY STATUS RESTARTS AGEdemoapp-557f47dccb-2gzvp 1/1 Running 0 41s$ oc rsh demoapp-557f47dccb-2gzvp bash(pod) $ env | grep -i passwordPASSWORD=encoded_secretUsing a prefixYou can also prefix your secrets in the pod using the --prefix option. This will add a prefix like mysql_ or our_prefix_ to all the key’s that are being added. Tis can be quite handy for example when you want to use the mysql app because that app expects all values to be prefixed.As an example, we will create a secret from-literal and then add it with a prefix:$ oc create secret generic prefix-example \\ --from-literal key=a_valuesecret/prefix-example createdAnd then we add it with the --prefix option:$ oc set env deployment/demoapp \\ --from secret/prefix-example \\ --prefix our_prefix_ \\deployment.extensions/demoapp updatedNow, when we enter the pod and echo the ENV variables we will see the key being prefixed:$ oc get pods -o namepod/demoapp-6c9b77c-dw4c2$ oc rsh pod/demoapp-6c9b77c-dw4c2 bash(pod) $ env | grep -i &#39;key&#39;our_prefix_KEY=a_valueSecret as file Warning: Mounting a volume on path that already exists on a pod will make all files in that directory inaccessibleTo create a volume that will hold the secret we use the oc set volume command:$ oc set volume \\ deployment/demoapp \\ --add \\ --type secret \\ --mount-path /etc/secret \\ --secret-name test-secret-literalinfo: Generated volume name: volume-zjmsqdeployment.extensions/demoapp volume updated We can see the mounted secret action from the pod in actions as well:$ rsh demoapp-557f47dccb-2gzvp bash(pod) $ cat /etc/secret/passwordencoded_secretAs you can see a file is created with the name of the key containing the value of the value from our secret.Closing thoughtsSecrets might not be as secret as you would hope but they provide a fundamental way of exposing sensitive data to our pods on OpenShift and you will certainly encounter them on a daily basis if you manage any kind of Container Cluster.See more of my EX280 and OpenShift related posts here https://docs.openshift.com/container-platform/4.9/nodes/pods/nodes-pods-secrets.html#nodes-pods-secrets-about_nodes-pods-secrets &amp;#8617; " }, { "title": "Creating my EX280 page on Jekyll", "url": "/posts/creating-a-ex280-page/", "categories": "Jekyll", "tags": "ex280, study", "date": "2022-01-15 00:00:00 +0100", "snippet": "As you might have notices I use Jekyll for this blog hosted on GitHub. I might do a post later on how I use it and how I set it up. For now, all you need to know is that Jekyll turns .md(markdown) file in to a blog. This happens using GitHub actions and builds my blog from source when I commit to main. Jekyll support some dynamic code to generate content and in this blog I will show you how I used that to generate an overview of all blog posted in a certain category.WhyAs part of my ongoing study’s I decided to give EX280 (Red Hat Certified Specialist in OpenShift Administration) a try. I wrapped up EX200 earlier to get familiar with the way RedHat does Remote testing and to get a feel for the style of question’s that are asked. I passed EX200 on the first try but wasn’t lucky on EX280 (getting 150 of 300 points on the first try, 210 are needed to pass).It was then that I thought back on something I red recently about learning: “Writing is thinking” (Ahrens2017)1So I decided that I would do some write ups on the core concepts that you need to know for EX280. I also thought It might warrant a special page on my blog to find it easily.HowI started by creating a new category in Jekyll. This is simply done by using setting a new category in the front matter of a markdown file:As an example, this is the front matter of this post:title: &quot;Creating my EX280 page on Jekyll&quot;toc: truemermaid: truecategories: [Jekyll]tags: [EX280, Study]Creating a tabNext up I created a tab in my Jekyll locals file, you can see that over here. The locals file for this blog is located at _data/locales.....# The tabs of sidebartabs: # format: &amp;lt;filename_without_extension&amp;gt;: &amp;lt;value&amp;gt; home: Home categories: Categories tags: Tags archives: Archives about: About....Creating the pageNext up I created a page in _tabs with some content explaining what the page was about. It’s the page you are now viewing and it’s located at _tabsDynamically filling the pageLast up was creating the overview of my EX280 posts on this new page. I did this using and modifying the following code:&amp;lt;div id=&quot;page-category&quot;&amp;gt; &amp;lt;h1 class=&quot;pl-lg-2&quot;&amp;gt; &amp;lt;i class=&quot;far fa-folder-open fa-fw text-muted&quot;&amp;gt;&amp;lt;/i&amp;gt; All EX280 Related post&#39;s &amp;lt;span class=&quot;lead text-muted pl-2&quot;&amp;gt;11&amp;lt;/span&amp;gt; &amp;lt;/h1&amp;gt; &amp;lt;ul class=&quot;post-content pl-0&quot;&amp;gt; &amp;lt;li class=&quot;d-flex justify-content-between pl-md-3 pr-md-3&quot;&amp;gt; &amp;lt;a href=&quot;/posts/customizing-project-creation-openshift/&quot;&amp;gt;Configuring default Project creation in Openshift&amp;lt;/a&amp;gt; &amp;lt;span class=&quot;dash flex-grow-1&quot;&amp;gt;&amp;lt;/span&amp;gt; &amp;lt;span class=&quot;text-muted small&quot;&amp;gt;2022-02-27 00:00:00 +0100&amp;lt;/span&amp;gt; &amp;lt;/li&amp;gt; &amp;lt;li class=&quot;d-flex justify-content-between pl-md-3 pr-md-3&quot;&amp;gt; &amp;lt;a href=&quot;/posts/controlling-network-access-in-openshift/&quot;&amp;gt;Controlling Ingress with Openshift Network Policy&#39;s&amp;lt;/a&amp;gt; &amp;lt;span class=&quot;dash flex-grow-1&quot;&amp;gt;&amp;lt;/span&amp;gt; &amp;lt;span class=&quot;text-muted small&quot;&amp;gt;2022-02-27 00:00:00 +0100&amp;lt;/span&amp;gt; &amp;lt;/li&amp;gt; &amp;lt;li class=&quot;d-flex justify-content-between pl-md-3 pr-md-3&quot;&amp;gt; &amp;lt;a href=&quot;/posts/exposing-services-with-routes-and-ssl/&quot;&amp;gt;Exposing services with routes and SSL&amp;lt;/a&amp;gt; &amp;lt;span class=&quot;dash flex-grow-1&quot;&amp;gt;&amp;lt;/span&amp;gt; &amp;lt;span class=&quot;text-muted small&quot;&amp;gt;2022-02-26 00:00:00 +0100&amp;lt;/span&amp;gt; &amp;lt;/li&amp;gt; &amp;lt;li class=&quot;d-flex justify-content-between pl-md-3 pr-md-3&quot;&amp;gt; &amp;lt;a href=&quot;/posts/setting-up-auth-and-users/&quot;&amp;gt;Manage users and policies, groups and permissions&amp;lt;/a&amp;gt; &amp;lt;span class=&quot;dash flex-grow-1&quot;&amp;gt;&amp;lt;/span&amp;gt; &amp;lt;span class=&quot;text-muted small&quot;&amp;gt;2022-02-20 00:00:00 +0100&amp;lt;/span&amp;gt; &amp;lt;/li&amp;gt; &amp;lt;li class=&quot;d-flex justify-content-between pl-md-3 pr-md-3&quot;&amp;gt; &amp;lt;a href=&quot;/posts/pod-affinity-and-anti-affinity/&quot;&amp;gt;Pod Affinity and Anti-affinity - Spreading out workloads&amp;lt;/a&amp;gt; &amp;lt;span class=&quot;dash flex-grow-1&quot;&amp;gt;&amp;lt;/span&amp;gt; &amp;lt;span class=&quot;text-muted small&quot;&amp;gt;2022-02-06 00:00:00 +0100&amp;lt;/span&amp;gt; &amp;lt;/li&amp;gt; &amp;lt;li class=&quot;d-flex justify-content-between pl-md-3 pr-md-3&quot;&amp;gt; &amp;lt;a href=&quot;/posts/quotas-limits-and-limit-ranges/&quot;&amp;gt;Quotas, limits and limit-ranges&amp;lt;/a&amp;gt; &amp;lt;span class=&quot;dash flex-grow-1&quot;&amp;gt;&amp;lt;/span&amp;gt; &amp;lt;span class=&quot;text-muted small&quot;&amp;gt;2022-01-29 00:00:00 +0100&amp;lt;/span&amp;gt; &amp;lt;/li&amp;gt; &amp;lt;li class=&quot;d-flex justify-content-between pl-md-3 pr-md-3&quot;&amp;gt; &amp;lt;a href=&quot;/posts/controlling-pod-rollout-and-scaling/&quot;&amp;gt;Scaling applications - Rollout, Scale and Auto-Scale Deployments&amp;lt;/a&amp;gt; &amp;lt;span class=&quot;dash flex-grow-1&quot;&amp;gt;&amp;lt;/span&amp;gt; &amp;lt;span class=&quot;text-muted small&quot;&amp;gt;2022-01-23 00:00:00 +0100&amp;lt;/span&amp;gt; &amp;lt;/li&amp;gt; &amp;lt;li class=&quot;d-flex justify-content-between pl-md-3 pr-md-3&quot;&amp;gt; &amp;lt;a href=&quot;/posts/troubelshooting-permissions-on-pods/&quot;&amp;gt;ServiceAccounts and SCCs - Running pods with more permission&#39;s&amp;lt;/a&amp;gt; &amp;lt;span class=&quot;dash flex-grow-1&quot;&amp;gt;&amp;lt;/span&amp;gt; &amp;lt;span class=&quot;text-muted small&quot;&amp;gt;2022-01-17 00:00:00 +0100&amp;lt;/span&amp;gt; &amp;lt;/li&amp;gt; &amp;lt;li class=&quot;d-flex justify-content-between pl-md-3 pr-md-3&quot;&amp;gt; &amp;lt;a href=&quot;/posts/create-and-use-secrets-openshift/&quot;&amp;gt;Creating and Using Secrets in OpenShift&amp;lt;/a&amp;gt; &amp;lt;span class=&quot;dash flex-grow-1&quot;&amp;gt;&amp;lt;/span&amp;gt; &amp;lt;span class=&quot;text-muted small&quot;&amp;gt;2022-01-16 00:00:00 +0100&amp;lt;/span&amp;gt; &amp;lt;/li&amp;gt; &amp;lt;li class=&quot;d-flex justify-content-between pl-md-3 pr-md-3&quot;&amp;gt; &amp;lt;a href=&quot;/posts/tolerating-tolerations-openshift/&quot;&amp;gt;Taints and Tolerations - Can&#39;t Pods and Nodes just get along?&amp;lt;/a&amp;gt; &amp;lt;span class=&quot;dash flex-grow-1&quot;&amp;gt;&amp;lt;/span&amp;gt; &amp;lt;span class=&quot;text-muted small&quot;&amp;gt;2022-01-12 00:00:00 +0100&amp;lt;/span&amp;gt; &amp;lt;/li&amp;gt; &amp;lt;li class=&quot;d-flex justify-content-between pl-md-3 pr-md-3&quot;&amp;gt; &amp;lt;a href=&quot;/posts/setting-config-maps-from-the-cli/&quot;&amp;gt;ConfigMaps - Setting ConfigMaps from the oc CLI&amp;lt;/a&amp;gt; &amp;lt;span class=&quot;dash flex-grow-1&quot;&amp;gt;&amp;lt;/span&amp;gt; &amp;lt;span class=&quot;text-muted small&quot;&amp;gt;2022-01-10 00:00:00 +0100&amp;lt;/span&amp;gt; &amp;lt;/li&amp;gt; &amp;lt;/ul&amp;gt;&amp;lt;/div&amp;gt;The most important this is the selector of the category: site.categories[&quot;EX280&quot;]. if you wanted to simply list a blog of you custom category (let’s call the example category foo) you could use: {% for post in site.categories[&quot;foo&quot;] %} &amp;lt;li&quot;&amp;gt; &amp;lt;a href=&quot;{{ post.url | relative_url }}&quot;&amp;gt;{{ post.title }}&amp;lt;/a&amp;gt; &amp;lt;/li&amp;gt; {% endfor %}Wrapping upSo that’s it. At the time of writing I have the first two EX280 post’s up but I have planed a few more. Check out the page at https://blog.benstein.nl/ex280/Update: It paid of. I passed the exam on my second try with 262/300 points. Ahrens, Sönke. How to Take Smart Notes: One Simple Technique to Boost Writing, Learning and Thinking: For Students, Academics and Nonfiction Book Writers. North Charleston, SC: CreateSpace, 2017. &amp;#8617; " }, { "title": "Taints and Tolerations - Can&#39;t Pods and Nodes just get along?", "url": "/posts/tolerating-tolerations-openshift/", "categories": "EX280", "tags": "openshift, kubernetes, ex280", "date": "2022-01-12 00:00:00 +0100", "snippet": "During my study for EX280 I found Taints and Tolerations very hard to understand. This is because Taints and Tolerations flip the scheduling of pods the other way around. What I mean by this is the following. Traditionally you would specify on a server what the server would run and what not. But in OpenShift this is flipped around. Instead of creating a list on a Server that allows or disallows apps to run we “taint” the node wit a key=value pair and a effect and let the scheduler sort out which pods are assigned to the node. How do we get a specifiek pod to run on a “tainted” node? We do this by “tolerating” the taint. For example; If we would taint a node with the following location:westus we could let a pod tolerate that this node is running at that location. ⚠️ FYI; this blog is written for Openshift but the theory is the same and most of the oc commands can be replaces with kubectlBut why?Using taints is a great way to dynamically schedule workloads across different nodes with different key:value pairs. A few examples could be: Nodes that are in a certain datacenter: location=datacenter01:PreferNoSchedule Nodes that have a special CPU: cpu=special:NoSchedule Nodes that we have a special place for in our heart: specialNode=true:NoExecuteWe can also combine different taints to get a specifiek selection of nodes that we want for our workload. Using taints can make scheduling your workloads a lot easier!Understanding the effectsA taint consist of key=value:effect. The effect are how the node will handle the taint1, if: NoSchedule is selected, Openshift wil not schedule pods on that node that do not tolerate the taint. Existing pods will keep running. PreferNoSchedule is selected, Openshift wil try not to schedule pods on the node that do not tolerate the taint. This is a great way to use taints without ending up with underutilized nodes. NoExecute is selected, Openshift will nog schedule pods that do not tolerate the taint. Openshift will also evict existing pods from the node. When you cordon a node in Openshift it basically gets this taint and asks all pods to get out of there. If there are pods that tolerate this taint then the additional paramater tolerationSeconds in the toleration can be parsed to allow the pod some time to shut down.In practiceSo now we know why, on to the how. You can follow along with these commands on a CRC instance or on a local K3s cluster. Don’t forget to change the command’s from oc to kube or kubectlTainting a nodeTainting a node is pretty easy. It’ done using the oc adm taint command:$ oc adm taint node crc-hsl9k-master-0 linux=good:NoSchedulenode/crc-hsl9k-master-0 taintedSo, now only pods that “tolerate” that linux=good will be scheduled on this node.Removing a taintUntainting a node can easily be done by adding a - after our taint command:$ oc adm taint node crc-hsl9k-master-0 linux=good:NoSchedule-node/crc-hsl9k-master-0 untainted The taint in actionLet’s spin up a pod and see the effect of our taint:$ oc new-project tainted-love$ oc new-app --name i-like-linux --docker-image bitnami/nginxIn my case this results in a pending pod because CRC is a one (1) node cluster. Great for this example. If you run multiple nodes and want to replicate the effect you should taint them all. Be aware that this will prevent other pods from running (even pods used by operators).The reason my pod is in pending?$ oc describe pod i-like-linux-968b9cdbc-n5lb6...Events: Type Reason Age From Message ---- ------ ---- ---- ------- Warning FailedScheduling 35s (x2 over 114s) default-scheduler 0/1 nodes are available: 1 node(s) had taint {linux: good}, that the pod didn&#39;t tolerate.Adding a toleration to a podAt the time of writing there is no easy CLI command to add a toleration to a pod or deployment. That means we will have to edit the yaml of the deployment. You can do this live by using oc edit deployment DEPLOYMENT_NAME or we can export the current config, edit it and send it back to the Cluster. Yeah, lets do that.Exporting the deployment yamlWe will export the deployment using oc get and the -o yaml flag. In the past there was an easy way to get the yaml without extra data but in this case we have to do it ourself:$ oc get deployment i-like-linux -o yaml &amp;gt; tolerate_app.yamlWe can now edit the file and add our toleration. Look for the spec of our container:spec:.... template:.... spec: progressDeadlineSeconds: 600 replicas: 1 revisionHistoryLimit: 10 selector: matchLabels: deployment: i-like-linux strategy: rollingUpdate: maxSurge: 25% maxUnavailable: 25% type: RollingUpdate template: metadata: annotations: openshift.io/generated-by: OpenShiftNewApp creationTimestamp: null labels: deployment: i-like-linux spec: containers: - image: bitnami/nginx@sha256:8f5062e816099c770d98613b95c86b4e1ac8d369712237a579fc3121225e55e2 imagePullPolicy: IfNotPresent name: i-like-linux ports: - containerPort: 8443 protocol: TCP - containerPort: 8080 protocol: TCP resources: {} terminationMessagePath: /dev/termination-log terminationMessagePolicy: File dnsPolicy: ClusterFirst restartPolicy: Always schedulerName: default-scheduler securityContext: {} terminationGracePeriodSeconds: 30....And add a toleration like (in this case I will be adding it under the spec.spec.dnsPolicy field):spec:.... template:.... spec: dnsPolicy: ClusterFirst tolerations: - key: linux value: good operator: Equal effect: NoSchedule....And patch that back to the cluster:$ oc apply -f tolerate_app.yamldeployment.apps/i-like-linux configured ⚠️ FYI; If you want to edit the yaml again you will need to re-export itAfter this our pod should be running$ NAME READY STATUS RESTARTS AGEi-like-linux-54b9b5fb7c-sndtx 1/1 Running 0 59s How does this workTaints and tolerations are matched by the scheduler of the cluster. In this case we gave the toleration of “Equal” (operator: Equal) to match with a node that has the same taint (key=linux and value=good). The effect (NoSchedule) must also match.WildcardsYou can also create a wild card toleration on a pod. This is done with the following values:spec:.... template:.... spec: tolerations: - effect: NoSchedule operator: ExistsOrspec:.... template:.... spec: tolerations: - key: linux operator: ExistsIn this case the Exits operator will only check if the taint or effect existst on the node 2There is even a way to tolerate all taints3 :spec:.... template:.... spec: tolerations: - operator: &quot;Exists&quot;Wraping upTaints are a great way to make the scheduling of your pods more predicable. It allows you designate specifiek nodes for specifiek workloads based on your usecase. There is a lot more to do with taints like combining them or applying them dynamically to nodes but I will not cover that in this blog. https://docs.openshift.com/container-platform/4.9/nodes/scheduling/nodes-scheduler-taints-tolerations.html &amp;#8617; https://docs.openshift.com/container-platform/4.9/nodes/scheduling/nodes-scheduler-taints-tolerations.html#nodes-scheduler-taints-tolerations-about_nodes-scheduler-taints-tolerations &amp;#8617; https://docs.openshift.com/container-platform/4.9/nodes/scheduling/nodes-scheduler-taints-tolerations.html#nodes-scheduler-taints-tolerations-all_nodes-scheduler-taints-tolerations &amp;#8617; " }, { "title": "ConfigMaps - Setting ConfigMaps from the oc CLI", "url": "/posts/setting-config-maps-from-the-cli/", "categories": "EX280", "tags": "openshift, kubernetes, ex280", "date": "2022-01-10 00:00:00 +0100", "snippet": "While preparing for EX280 I learned a lot about using the CLI to configure Openshift resources. It’s always great learning to configure this stuff from the CLI because it gives you so much power and (In my opinion) a lot more understanding about how things work because you need to viluazie what you are doing in your head. Also: “Writing is thinking” (Ahrens2017)1FYI; This blog is written for OpenShift but for most command’s oc and kubectl are interchangeable.Understanding ConfigMaps and SecretsIn Kubernetes you can create ConfigMaps and Secrets to supply your pod’s with “information”. ConfigMaps and Secret’s look a lot alike with the major difference at this point being that Secrets encode (not encrypt) their values in base64In this blog I’ll talk about creating ConfigMap’s and how to mount and use them. The command’s for secrets look a lot like these but I’ll save that for some other time.Adding data to a pod using a ConfigMapIn this example we will supply a ENV key called “api_url” to a deployment. We will also add a webserver config file to the deployment.This will look like this:graph TD subgraph Namespace subgraph Deployment A[Deployment] --&amp;gt; |Creates| B B[ReplicaSet] --&amp;gt; |Manages| C C[Pod] end D[ConfigMap: application-env] --&amp;gt; |Supplies Data| C E[ConfigMap: application-config] ---&amp;gt; |Supplies Data| C endPreparing the environmentSo, if not clear already, you can do this on you own cluster or local K3s setup. We will use the bintami/nginx image as Deployment because it’s nice and easyCreating the deploymentFor this we will create a a new project and deploy the application with:$ oc new-project configmaps-demo$ oc new-app --name super-app --docker-image bitnami/nginxThis should resolve in a running nginx container called super-app:$ oc get podsNAME READY STATUS RESTARTS AGEsuper-app-67b7c69cfb-v5rr7 1/1 Running 0 8Creating the ConfigMap’sWe will create 2 config maps for this example: application-env containing api_url=https://api.amazing.com application-config containing our simple string “I am your config”We will create the application-env ConfigMap form the CLI with:$ oc create configmap application-env \\ --from-literal api_url=https://api.amazing.comAnd we will create the application-config ConfigMap from a simple file containing some string data:$ echo &quot;I am your config&quot; &amp;gt; config.txt$ oc create configmap application-config \\ --from-file config.txtAdding config maps using the CLINow for the magic 🎩. We will add both config maps to our app super-app using the oc command line.Adding the ConfigMap as ENV variablesYou do this with the following command:$ oc set env deployment/super-app \\ --from configmap/application-envThis will provide the KeyPair as values to the container. There a two ways to see the results. Check the pod spec with $ oc get pods NAME READY STATUS RESTARTS AGE super-app-67b7c69cfb-v5rr7 1/1 Running 0 8 $ oc get pod super-app-67b7c69cfb-v5rr7 -o yaml | grep -A 4 -e &#39;env:&#39; - env: - name: API_URL valueFrom: configMapKeyRef: key: api_url Connect to the pod and echo the ENV variables $ oc get pods NAME READY STATUS RESTARTS AGE super-app-67b7c69cfb-v5rr7 1/1 Running 0 8 $ oc rsh super-app-67b7c69cfb-v5rr7 bash (pod) $ echo $API_URL https://api.amazing.com Adding the ConfigMap as fileThis is done with a slightly longer command. The following wil create a volume for the pod to mount and acces the files: ⚠️ When mounting a volume to a pod all data on the mount path will be made inaccessible. This means that any files present at /mount/config/application-config will not show up in your pod$ oc set volume deployment/super-app \\ --add \\ --type configmap \\ --mount-path /mount/config/application-config \\ --configmap-name application-configThis will map the ConfigMap to our pod using the new Volume. We can see the result by connecting to the pod:$ oc get podsNAME READY STATUS RESTARTS AGEsuper-app-67b7c69cfb-v5rr7 1/1 Running 0 7m8s$ oc rsh super-app-67b7c69cfb-v5rr7 bashNo we can cat the mounted file:(pod) $ cat /mount/config/application-config/config.txt I am your configWe can also see this mount in the yaml of our pod:$ oc get podsNAME READY STATUS RESTARTS AGEsuper-app-79fc5bf5df-zsjlg 1/1 Running 0 12m$ oc get pods super-app-79fc5bf5df-zsjlg -o yaml | grep mountPath -A 2 - mountPath: /mount/config/application-config name: volume-qcxd4 - mountPath: /var/run/secrets/kubernetes.io/serviceaccount name: kube-api-access-wddx2 readOnly: trueConfigMaps and multible keysPlease note that the config is being mounted as config.txt. This is because when we created the ConfigMap from file we did not asigne the contents of the file to a key. When you oc describe the config map you can see that the contents has been “keyed” to config.txt:$ oc describe configmaps application-configName: application-configNamespace: configmaps-demoLabels: &amp;lt;none&amp;gt;Annotations: &amp;lt;none&amp;gt;Data====config.txt:----I am your config If we wanted to mount multible files we could add more key value pairs to a single config map like:$ echo &quot;I am your users&quot; &amp;gt; users.txt$ echo &quot;I am your list&quot; &amp;gt; list.txt$ oc create configmap application-config-multible \\ --from-file config.txt \\ --from-file users.txt \\ --from-file list.txt $ oc describe configmap application-config-multibleName: application-config-multibleNamespace: configmaps-demoLabels: &amp;lt;none&amp;gt;Annotations: &amp;lt;none&amp;gt;Data====config.txt:----I am your configlist.txt:----I am your listusers.txt:----I am your usersEvents: &amp;lt;none&amp;gt; And mount it to the pod (on a different path):$ oc set volume deployment/super-app \\ --add \\ --type configmap \\ --mount-path /mount/config/application-config-multible \\ --configmap-name application-config-multibleNow from the pod you’ll see the files mounted to /mount/config/application-config-multible:(pod) $ ls -la /mount/config/application-config-multibletotal 0drwxrwsrwx. 3 root 1000150000 110 Jan 11 09:40 .drwxr-xr-x. 3 root root 41 Jan 11 09:40 ..drwxr-sr-x. 2 root 1000150000 57 Jan 11 09:40 ..2022_01_11_09_40_51.324279541lrwxrwxrwx. 1 root root 31 Jan 11 09:40 ..data -&amp;gt; ..2022_01_11_09_40_51.324279541lrwxrwxrwx. 1 root root 17 Jan 11 09:40 config.txt -&amp;gt; ..data/config.txtlrwxrwxrwx. 1 root root 15 Jan 11 09:40 list.txt -&amp;gt; ..data/list.txtlrwxrwxrwx. 1 root root 16 Jan 11 09:40 users.txt -&amp;gt; ..data/users.txtWrapping upSo that’s it for now. As you can see we can use ConfigMap’s to supply pods with different kinds of information. We can add ENV data and provide files to the pods using a ConfigMap. You can use almost the same commands to add the data using Secrets but I’ll cover that in another blog you can read about that here https://blog.benstein.nl/posts/create-and-use-secrets-openshift/. Ahrens, Sönke. How to Take Smart Notes: One Simple Technique to Boost Writing, Learning and Thinking: For Students, Academics and Nonfiction Book Writers. North Charleston, SC: CreateSpace, 2017. &amp;#8617; " }, { "title": "Installing vim-plug on macOS", "url": "/posts/installing-plug-vim-on-macos/", "categories": "Commandline", "tags": "vim, macos", "date": "2022-01-04 00:00:00 +0100", "snippet": "vim-plug is a VIM plug-in manager to install themes and other plug-ins in VIM. It’s the most populair one at the moment.InstallationTo install vim-plug you can go over to https://github.com/junegunn/vim-plug and run the following command:$ curl -fLo ~/.vim/autoload/plug.vim --create-dirs \\ https://raw.githubusercontent.com/junegunn/vim-plug/master/plug.vim This will create a autoload directory and place plug.vim in it.ConfigurationTo enable the loading of plug-ins you need to add the loading code to your vimrc. If you already have one you can add it with:$ vim ~/.vimrc Add:# vimrccall plug#begin()Plug &#39;tpope/vim-sensible&#39;call plug#end()Installing a themeI installed vim-plug to easily add a theme to my vim setup. I chose the theme https://github.com/sonph/onehalf/tree/master/vimYou can install the theme by adding the plug to you vimrc# vimrccall plug#begin()Plug &#39;tpope/vim-sensible&#39;Plug &#39;sonph/onehalf&#39;, { &#39;rtp&#39;: &#39;vim&#39; }call plug#end()colorscheme onehalfdarklet g:airline_theme=&#39;onehalfdark&#39; Note: When using and installing new plug’s you might need to update plug from vim commando mode with:bash:PlugUpdate" }, { "title": "Let&#39;s get fuzzys", "url": "/posts/lets-get-fuzzy/", "categories": "Commandline", "tags": "cli, linux", "date": "2021-12-07 00:00:00 +0100", "snippet": "Fuzzy search is a great and easy way to find (back) stuff. You can use fzf on macOS and Linux to replace bash/zsh bck-i-search, make find obsolete and even get a quick way to preview files on the command line.Installing on macOSWe can install fzfusing brew:brew install fzfEnable integrationAfter installation (and a reload of our shell with source ~/.zshrc) we can use fzfas is or we can integrate it with our shell.To “install” fzf in the shell run:/usr/local/opt/fzf/installSite note: When using oh-my-zsh you can enable fzf by adding it to you plug-in list. I had some bad experience with it so I’m doing it the manual way.During install fzf will ask you if you want key-bindings. This will replace CRTL + r and CTRL + R for reverse search.Cool tricksWhen invoking fzf in any directory it will act like find . | fzf . fzf will build a cache with underlining files. As an example I created 10 directory’s with 10 files in them using:$ mkdir fzf_dir_{1..10}$ touch fzf_dir_{1..10}/file_{1..10}When invoking fzfin this directory you can actively search all underlying folders and files:Using Previewfzf even has a build in preview function. You can use it with cat or (even beter) with bat: With cat: fzf --preview &#39;cat {}&#39; With bat: fzf --preview &#39;bat --style=numbers --color=always --line-range :500 {}&#39;(tip: alias that last one to something like fbat or pfzf)Setting up a a fuzzy alias for historyfzf has the option to replace reverser search on your shell. I don’t like this because it changes the default behaivor of the zsh shell. Instead I created the following alias in my .zshrc shell:## Manual alias for history search using fzfalias ff=&quot;print -z -- \\$(cat ~/.zsh_history | cut -d &#39;;&#39; -f2 | fzf --height 40% --border)&quot;A great thing about this alias is that it searches your history in a small window on the shell and returns the selected result to the shell (instead of running it). This gives you the option to review a command before running it:" }, { "title": "Quick open Things3 with Alfred", "url": "/posts/using-alfred-to-open-things-lists/", "categories": "Productivity", "tags": "things3, alfred, macos", "date": "2021-09-27 00:00:00 +0200", "snippet": "In my daily workflow I have found that when using different tools and systems with each other removing friction can be key. This is not a original insight or even a leap of the imagination but I do find myself eliminating friction in workflows in new ways. One of those ways I recently Implemented is to use Alfred on the Mac to quickly jump to lists or filter in my preferred ToDo app Things3.This is how it worksThings3 URL SchemeYou can easily create custom URL schemes using the Things3 URL Scheme Creator . Using the things/// will tell you macOS or iOS device to use the Things app to open the action. Some examples of Query’s I use on the daily: things:///show?id=inbox To show the Inbox things:///show?query=WORK%20-%20JIRA To show the list WORK - JIRA from Things things:///show?id=today&amp;amp;filter=WORK To show ToDo’s that are scheduled for Today with the tag WORKYou can add these URL’s to any place that allows links so you can even add links from .md documents or text documents to refer to projects which can be a great workflow.Alfred open URL ActionOpening URL’s with Alfred is easy using a custom workflow. To focus the app and make sure it’s running I include the open app action in my workflow.I use the - sign as a prefix to trigger the workflow. Using the list filter you can add Query’s to the workflow:Putting it togetherA simple workflow get’s a simple demo, this is how mine works. When the Keyword - is activated it pop’s up a list of all my saved search query’s. Choosing one of these will open Things3 to that list" }, { "title": "Using netcat to replace telnet", "url": "/posts/Telnet-is-dead-long-live-netcat/", "categories": "Commandline", "tags": "cli, linux", "date": "2021-09-12 00:00:00 +0200", "snippet": "Any longtime computer user might be familiarity with the (ab)use of the telnet command to check connections and open ports. It is certainly still the first program that pops in to my mind when I want to check a network adres or port. But telnet was removed from Windows a long time ago and should not be installed on any *nix system. Luckily there is a much older and beter program available.Enter netcatnetcat is an old school Unix util that (just like whiskey) gets better with the years. It’s a great way to check open ports and troubleshoot connectionsNetcat syntaxThe netcat syntax is pretty straight forward:nc OPTIONS TARGET PORT_RANGE Example:$ nc -v google.com 80 Connection to google.com port 80 [tcp/http] succeeded!Netcat optionsnetcat has some options that are quite handy: -v &amp;amp; -vv give you a verbose and more verbose output. Hint, without a -v flag you will not see the succeeded message -u toggles from TCP to UDP -w n changes the wait time to n. So -w 1 will set a 1 second timeout -n gives you the option to scan a IPHow to useHere a some examples of how to use nc:Scanning a port on a host$ nc -vv google.nl 80Connection to google.com port 80 [tcp/http] succeeded!Scanning a port range on a local host$ nc -vv -n -z -w 1 10.1.1.1 50-60nc: connectx to 10.1.1.1 port 50 (tcp) failed: Connection refusednc: connectx to 10.1.1.1 port 51 (tcp) failed: Connection refusednc: connectx to 10.1.1.1 port 52 (tcp) failed: Connection refusedConnection to 10.1.1.1 port 53 [tcp/*] succeeded!nc: connectx to 10.1.1.1 port 54 (tcp) failed: Connection refusednc: connectx to 10.1.1.1 port 55 (tcp) failed: Connection refusednc: connectx to 10.1.1.1 port 56 (tcp) failed: Connection refusednc: connectx to 10.1.1.1 port 57 (tcp) failed: Connection refusednc: connectx to 10.1.1.1 port 58 (tcp) failed: Connection refusednc: connectx to 10.1.1.1 port 59 (tcp) failed: Connection refusednc: connectx to 10.1.1.1 port 60 (tcp) failed: Connection refused" }, { "title": "How to customize the appearance of tags in Obsidian", "url": "/posts/Custom-tags-in-Obsidian/", "categories": "Obsidian", "tags": "customization", "date": "2021-04-21 00:00:00 +0200", "snippet": "In this note I wil show and tell how to change the appearance of certain Tag’s based on the content of the Tag using CSSCustomizingNow you can create custom tag’s that match on you existing tag’s. I’m using a simple evergreen system to show the status of my notes. In this instance I’m going to map the following tag’s: #Evergreen/Seedling → 🌱 SEEDLING #Evergreen/Sapling → 🪵 SAPLING #Evergreen/Evergreen → 🌲 EVERGREENI’m also going to change the background color of the tag, just to let it stand out a bit more.Creating a custom css fileYou can easily add custom CSS to Obsidian using CSS Snippets. These are located in your vault located in the vault/.obsidian/snippets/. Create a custom file (for example customTags.css) and enable the snippet in Obsidian settings. See the official documentation over at https://help.obsidian.md/Advanced+topics/Customizing+CSS .Creating custom tag’sUsing the following CSS code we can easily create the custom Tag’s:This will map the CSS to the tag’s and will create the following output:Feel free to play around with your own CSS hacks! Obsidian.md is a great tool that’s easily customized.Found this help-full? Checkout my GitHub or buy me a Coffee over at BuyMeACoffee" }, { "title": "Using AppleScript to quick add Things3 to Fantastical3", "url": "/posts/things3-to-fantastical3/", "categories": "Productivity", "tags": "macos, things3, fantastical", "date": "2021-04-01 00:00:00 +0200", "snippet": "Calendar blocking (the process of marking of pieces of time in your calendar to work on a given task) can be a real productivity booster. Not only does it help you in planning out your day it also creates a visible representation of what you have done in a week.Because I already keep track of the things I want to do in the amazing task app Things3 I added a simple workflow to copy over selected todo’s to my calendar app of choice Fantastical. This keeps the content of my todo’s consistent and removes a lot of friction with daily and weekly planning.Adding custom scripts to Things3Things has a great option to add custom script to the menu bar of the application. This is done by: Quitting Things Creating the directory ~/Library/Application Support/Cultured Code/Things Scripts using the Terminal: $ mkdir ~/Library/Containers/com.culturedcode.ThingsMac/Data/Library/Application\\ Support/Cultured\\ Code/Things\\ Scripts Change to the dir using: $ cd ~/Library/Containers/com.culturedcode.ThingsMac/Data/Library/Application\\ Support/Cultured\\ Code/Things\\ Scripts Now you can add custom scripts to this directoryCreating the scriptIn the directory ~/Library/Containers/com.culturedcode.ThingsMac/Data/Library/Application Support create the script addToFantastical.scpt:More information about adding scripts can be found on the official support pageRunning the scriptThe script can be accessed from the things3 menu: ❗ When you run these script’s for the first time macOS will ask you for permissionsRunning the script will: Copy the name and note of the current selected todo Open up Fantastical in quick add mode Add a event with the name of the todo using the note of the todo as extra content and will set a 1 hour duration of the eventYou can customize the script if you like to change the duration of the event or to add the event to a specifiek calendar. For more information see the Dictionary page of the Fantastical app in the AppleScript editor." }, { "title": "Using Alfred and qlmarkdown to Quicklook .md files in macOS", "url": "/posts/Using-Alfred-and-qlmarkdown-copy/", "categories": "Productivity", "tags": "macos, alfred", "date": "2020-11-27 00:00:00 +0100", "snippet": "I have been using Alfred more and more during the past months and I’ve been looking for a quick way to view little snippets of information with it. I use a few ‘cheat sheets’ for commands and application I use where I’m not always sure of the right command or syntax.Cheat sheetsI have been creating very simple .md markdown sheets for a few command’s I use a lot. We will use the Atlassin text syntax as an example. I created the following markdown file:- `*strong*` → Makes text strong.- `_emphasis_` → Makes text emphasis..- `??citation??` → Makes text in citation.- `-deleted-` → Makes text as deleted.- `+inserted+` → Makes text as inserted.- `^superscript^` → Makes text in superscript.- `~subscript~` → Makes text in subscript.- `` → Makes text as monospaced.Putting text in red{color:red} look ma, red text!{color}Previewing .md files on macOSTo preview a markdown file on macOS with rendering you’ll need to install qlmarkdown. When installed this will enable the build in macOS Quicklook to render markdown files in the preview window.Calling Cheat Sheets using AlfredUsing an Alfred ‘File Filter’ + ‘Run Script’ action you can easily list files in a directory. The Run Script action will then perform the command-line version of Quicklook on the file using the following command:qlmanage -p $query Setting up the workflow in Alfred will look like this: The Workflow in Alfred Settings for the File Filter, drag the folder you want to look in into the option scope Settings for the Run Script Putting it all togetherOnce this is all set-up you can easily create simple markdown cheat sheets and call them using Alfred" }, { "title": "Using RescueTime and Alfred for easy focus sessions", "url": "/posts/RescueTime-Worflow/", "categories": "Productivity", "tags": "rescuetime, alfred, macos", "date": "2020-11-24 00:00:00 +0100", "snippet": "During the last weeks of working from home I have been using the FocusTime feature of RescueTime a lot more. I use these timeblocks (20 minutes for example) to focus in on specific tasks or to create a timebox where I can work trough a small set of problems. For this I have been using RescueTime (Premium) Alfred IFTTT A TimeTimerOverviewThe workflow is quite simple. I set a TimeTime to the time I want to focus. I use the TimeTimer as a visual aid to see my progress. I then use Alfred and quick workflow I create to tigger the RescueTime API. The source code can be found at https://github.com/KingOfSpades/FocusStarterThis kicks of the following eventsI use a IFTTT workflow to trigger a calendar event creation for in the weekly review and I use a TimeTimer as a visual aid.The WhyWhy am I using all this? Well the RescueTime FocusTime feature blocks all distracting websites during a session which is kind of neat. It also gives me some traceability of how productive my day has been and keeps me accountable.The HowSetting up RescueTimeNot much setup needed. If you have a RescueTime account on https://www.rescuetime.com you can get started setting everything up.Setting up SlackGo to the integrations page on RescueTime (https://www.rescuetime.com/anapi/setup/overview) to setup the Slack integration. RescueTime wil now set your status to Do Not Disturb when using the Focus TimeCalling the APIYou’ll need an API get call the API and use the Alfred workflow, create the API key at https://www.rescuetime.com/anapi/manage and het the workflow from my GitHub page (you can also incorporate the API command’s in your own script) at https://github.com/KingOfSpades/FocusStarterWhen you have a key you can easily use the API key to start a focus session, example:curl --location --request POST \\&#39;https://www.rescuetime.com/anapi/start_focustime?key=&amp;lt;your_api_key&amp;gt;&amp;amp;duration=20&#39;or to stop a session, example:curl --location --request POST \\&#39;https://www.rescuetime.com/anapi/end_focustime?key=&amp;lt;your_api_key&amp;gt;&#39;More information at https://www.rescuetime.com/apidoc . You an also use the API to get feedback on your daily RescueTime score, checkout my BitBar plugin rescueTimeBar at https://github.com/KingOfSpades/rescueTimeBarIFTTT Trigger (optional)I setup a IFTTT trigger to create a calendar event when I start a Focus session. This helps me to trace my use of focus time trough the week. You can set it up at IFTTT. I’m planning to replace this with a integrated option in my Alfred workflow in the future.ClosingI really enjoy the speed that I can trigger a focus session at the moment. It really eliminated almost all the friction between “I should do a focus moment” and “I’m doing a focus moment”. In the future I would like to expend the workflow so it also triggers DND on macOS and I want to replace the IFTTT trigger with something local. Maybe I’ll even add a little “On the Air” light to my setup." }, { "title": "Simple DIY Wood Palmrest", "url": "/posts/DIY-Palmrest/", "categories": "Productivity", "tags": "customization", "date": "2020-03-25 00:00:00 +0100", "snippet": "With the Corona crisis in full swing (which forces us all to work from home) I decided I needed a palm rest for my 60% AnnePro2. Not being willing to shell out 20-40 dollars on a plastic one that would ship next week I decided to take to the internet and some good old handy work. Being inspired by [https://medium.com/@vveleva/diy-free-ish-wooden-keyboard-wrist-rest-8b902a7f6d26] I decided to give it a try.MaterialsAfter doings some basic measurements I went to to hardware store to find some scrap woud (they somethimes offer these at local hardware store). I found a piece that fit almost perfectly and after taking a bit off I was happySanding and shapingTrue to the tutorial I mapped of a simple edge and sanded it down. I also added soma anti slipping rubbers.FinishingI decided to apply a bit of wood oil I had left from Ikea. It gave it a light finish and didn’t make it to slickFinal ResultPretty happy with it" }, { "title": "SSH Keys and Auth - Part 1 of 3", "url": "/posts/SSH-Keys-and-Auth-Part-1/", "categories": "Commandline", "tags": "cli, linux, macos", "date": "2020-02-07 00:00:00 +0100", "snippet": "In this ‘back to basics’ blog entry we’re going to talk about setting up SSH keys. SSH keys are used for logging in to stuff and authorizing to other stuff (like GiT). You can create a PRIVATE PULBIC keypair and share the PUBLIC key with the world!Note, this guide is bases on macOSGetting started Start by opening a terminal. Use the following command to generate a 4096 bit RSA key with you e-mail-address as the leu comment. Key-comments are optioneel and can be found at the end of public key. They help a lot with identifying keys so use them! You can use a e-mail to identify a key or anything else you like:ssh-keygen -t rsa -b 4096 -C &quot;your_email@example.com&quot;Sidenote, ed25519 is up and coming to replace RSA as the default encryption protocol. At this point a lot of automation does not yet accept these keys for authentication (Like Azure DevOps GiT and Azure Resource Templates). That’s why we’re using RSA at this point. You can choose where to save the key. Accept the default location or choose your own:Enter a file in which to save the key (/Users/you/.ssh/id_rsa): [Press enter] Now you get the option to set a phassphrase. This is a password that encrypts your private key. Please do so: Enter passphrase (empty for no passphrase): [Type a passphrase]Enter same passphrase again: [Type passphrase again] The PRIVATE PUBLIC pair has now been created. If you accepted the default location and name you will find 2 files in ~/.ssh id_rsa id_rsa.pubAdding the key to you SSH AgentAdding keys to your agent is pretty easy, use this command to start the agent:eval &quot;$(ssh-agent -s)&quot;&amp;gt; Agent pid 59566Use this to load the file:ssh-add ~/.ssh/NameOfKeyBonus, (when on macOS 10.12.2 or newer, edit the config file in ~/.ssh/config to include:Host * AddKeysToAgent yes UseKeychain yes IdentityFile ~/.ssh/id_rsaAfter doing this, add your key using:ssh-add -K ~/.ssh/NameOfKeyUsing you public keyNow to the last step. You have to ‘distribute’ you SSH Public Key. SSH keys are mostly used to authenticate to GiT repository’s or Linux server. You can also include a public key in most automated deployments on Azure and AWS.If you want to add your public key to a Linux VM you can do this by adding it to the /home/user/.ssh/authorized_keys of the user you want to login with.Bonus. On macOS use this command to copy your key to your Clipboard:pbcopy &amp;lt; .ssh/NameOfKey.pubAfter adding the key to your keychain and adding it to the server you should be able to login using:ssh user@computer.domeinYou can also use this command to test the login:ssh -T user@computer.domeinAnd you can specify the key to use if you’d like (more on this in part 2, working with SSH CONF)ssh -i .ssh/NameOfKey user@computer.domein" }, { "title": "Primer on YAML", "url": "/posts/Primer-on-YAML/", "categories": "Commandline", "tags": "cli, yaml", "date": "2019-11-03 00:00:00 +0100", "snippet": "It’s always good to write down the basics, rehearse the syntax and go trough the motions. So let’s do that with YAML.YAML is a data serialisation language. It’s used to store and display information. I always think of it as JSON 2.0 . You can create value pairs in YAML like: lists values objectsYAML files are identfied by the extenion .yml and .yaml . You can use # for comments and you want to start of with a --- on top. YAML is used by a lot of software like Ansible.Creating object’s in YAMLLet’s start with an example or a car. We are going to create an object called myCar and fill it up with some information:myCar: name: &quot;My cool car&quot; function: &quot;driving&quot; wheels: 4 gallonPerMile: 7.6 apk: true buildDate: 2019-06-04 14:33:22 broken: nullNo we created a car object myCar . All child items that are indented (meaning they are 2 spaces to the right under myCar ) are part of the myCar object. You can use a lot of different datatype in YAML. In the myCar object we are using:STRING —&amp;gt; nameINT —&amp;gt; wheelsBOOL —&amp;gt; APKDATE —&amp;gt; buildDateFLOAT —&amp;gt; gallonPerMileMaking a list, checking it onceUsing YAML we can also use lists. Image we have 3 drivers that are registered to myCar. We can create a list of drivers using the following notations:Driver list using indent:drivers: - Bob - Frank - MargretWe can also create a list on a single line using:drivers: [&quot;Bob&quot;, &quot;Frank&quot;, &quot;Margret&quot;]You can even go one step further and an object in to a list using:drivers: - name: &quot;Bob&quot; age: 23 canDrive: true - name: &quot;Frank&quot; age: 41 canDrive: false - name: &quot;Margret&quot; age: 33 canDrive: trueThis can also be done using inline style:drivers: - {name: &quot;Bob&quot;, age: 23, canDrive: true}Text renderingYAML has been built to be readable and to take up a small space on you screen. This is primarily done so you can have multiple files open next to each-other (especially handy when using git and comparing different versions). To this extend there are few cool functions build in to YAML, like:Rendering text to a single lineExample. What if one of our drivers has a complicated backstory. One of lipsum’s and lorems. In YAML you can break up this blok to make it more readable for you (human):- name: &quot;Margret&quot; age: 33 canDrive: true backStory: Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur.Now, for some reason you want to render this textblok to be displayed on one line? No problem, ad a &amp;gt; after backStory . Example:- name: &quot;Margret&quot; age: 33 canDrive: true backStory: &amp;gt; Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.Now, on rendering, this will be displayed as one long line.Rendering text while preserving formattingAlmost the opposite of the single line option, using | after backStory will render the text including all formatting (newlines and tabs included). Example:- name: &quot;Margret&quot; age: 33 canDrive: true backStory: | Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Will print out the example above with all the crazy spacingAnchorsYou can use anchors &amp;amp; to recall information later. For example, we started giving Margret the age of 33. Maybe we want to reuse that information later. We can do so by using an anchor like:- name: &quot;Margret&quot; age: &amp;amp;age 33 canDrive: trueNow we are going to calculate how long she had her driving licence. We going to add the age she got it and then calculate it:- name: &quot;Margret&quot; age: &amp;amp;age 33 obtainedLicenceAt: &amp;amp;gotLicenceAt 19 allowedToDriveSinceYears: *age - *gotLicenceAt canDrive: trueYou can also anchor an entire object. So, if you have a car and want 2 cars of a different make you can do:baseCar: &amp;amp;base wheels: 4 needsDriver: truehondaCar: &amp;lt;&amp;lt;: *base manufacturer: &quot;Honda&quot;teslaCar: &amp;lt;&amp;lt;: *base manufacturer: &quot;Tesla&quot; type: &quot;⚡️&quot;This creates a base car with a few values. Then we use &amp;lt;&amp;lt;: *base to anchor it back to baseCar. You can also add extra values after that.Converting datatypesYAML will do it’s best to identify datatypes based on your input. If your don’t want it to to that you can force a date type like:myCar: wheels: !!float 4 gallonPerMile: !!str 7.6Using these additions will force the wheels to be seen as a float (as 4.0) and the gallonPerMile to be seen as a string. More conversion options over at: https://github.com/yaml/YAML2/wiki/Type-casting" }, { "title": "DIY Personal CI/CD Pipline", "url": "/posts/DIY-Personal-CICD-Pipline/", "categories": "Productivity", "tags": "azure, devops", "date": "2019-10-16 00:00:00 +0200", "snippet": "Using Docker, Azure DevOps and Azure Container Instances we are going to setup a simple pipe-line that will build our image from code to Docker image, tag and push that image to a private Azure Container Registry and deploy the latest version of said container to a Azure Container Instance. I use this personally for a few small projects like my personal dashboard. I edit, run and test the code on my local machine using Docker and then commit the code my DevOps GiT repository.This looks a little like this:IngredientsSome pre requirements. This guide assumes you are using Azure DevOps and DevOps GiT. You also need to link your DevOps environment to your Azure Subscription. Details for DevOps and DevOps GiT are here:DevOps SetupAnd more on adding Azure to your DevOps environment is here:So before we get started, check if you have the following: Add Azure to DevOps Pipeline Active Azure environment; Azure DevOps; Azure DevOps Service set up to connect to your Azure environment; Az CLI installed on you system (see: Installing Azure CLI) . You can also use the Azure Web CLI from your Azure Portal.Some notes, I’m using &amp;lt;Placeholder&amp;gt; to indicate places where you need to provide code. I’m also using Azure CLI in BASH so I’ll be using \\ to do linebreaks. Replace them with backticks ` if you’re using PowerShell.Setting up AzureIn your Azure environment we are going to setup a Private Azure Container Registry and a Resource Group to deploy your Container instance, get started by login in: az loginAfter login in create your resource group az group create \\ --location &quot;West Europe&quot; \\ --name RG-ContainerInstance \\ --tags CiCDTutorialNow we are going to create the Private Container Repository az acr create \\ --name PrivateRepository \\ --resource-group RG-ContainerInstance \\ --sku Basic \\ --admin-enabled true \\ --tags CiCDTutorialNow (from the Azure Portal) go to Dashboard &amp;gt; Container registries &amp;gt; PrivateRepository - Access keys :Note down the following: Login server Username PasswordYou’ll need this in your Build pipeline.Now we’re done on the Azure side. Time to switch over to Azure DevOpsSetting up DevOps PipelineIn Azure DevOps navigate to your project and go to Pipelines &amp;gt; Builds. We are going to setup a pipeline that is triggered by a commit to the Master Branch. Select New and then New Build Pipeline .Select your source (in this case I’m using Azure Repos)After selecting your repo chose a Starter pipelineAfter this you are presented with the basic pipeline YAML. Replace the YAML with the following code # Starter pipeline # Start with a minimal pipeline that you can customize to build and deploy your code. # Add steps that build, run tests, deploy, and more: # https://aka.ms/yaml trigger: - master pool: vmImage: &#39;ubuntu-latest&#39; steps: - script: echo Building and Pusing image displayName: &#39;Building and Pusing image&#39; - task: Docker@2 inputs: containerRegistry: &#39;Azure Docker Repository&#39; repository: &#39;YourRepository&#39; command: &#39;buildAndPush&#39; Dockerfile: &#39;**/Dockerfile&#39; tags: &#39;latest&#39; - task: AzureCLI@2 inputs: azureSubscription: &#39;&amp;lt;YourSubscriptionName&amp;gt; (&amp;lt;YourSubscriptionID&amp;gt;)&#39; scriptType: &#39;bash&#39; scriptLocation: &#39;inlineScript&#39; inlineScript: | az container delete \\ --name YourContainerInstance \\ --resource-group RG-ContainerInstance \\ --yes - task: AzureCLI@2 inputs: azureSubscription: &#39;&amp;lt;YourSubscriptionName&amp;gt; (&amp;lt;YourSubscriptionID&amp;gt;)&#39; scriptType: &#39;bash&#39; scriptLocation: &#39;inlineScript&#39; inlineScript: | az container create \\ --image &amp;lt;Login server&amp;gt;/YourRepository \\ --registry-login-server &amp;lt;Login server&amp;gt; \\ --registry-username &amp;lt;Username&amp;gt; \\ --registry-password &amp;lt;Password&amp;gt; \\ --resource-group RG-ContainerInstance \\ --name YourContainerInstance \\ --cpu 0.5 \\ --memory 1 \\ --ports 3030 \\ --environment-variables GEMS=uptimerobot \\ --restart-policy always \\ --dns-name-label YourDNSLabel \\ --restart-policy always \\ --tags CiCDTutorial In this case I’m deploying a Docker image and giving it 0.5 CPU , 1 GB RAM, Parsing in some ENV variables and exposing port 3030. You can customize this to your liking. You can find more details on creating Azure Container Instances on the Docs pageThis pipline will do the following steps: Build a Docker image acoarding to the Dockerfile in the root of your GiT Repo; Tag that image as latest and push it to you private Repository In case that your current Container Instance is running the first Azure CLI command will delete it; Deploy a new Container Instance named YourContainerInstance with a few extra variables.After the deployment you can check if your image is running using az container list --output table" }, { "title": "Fixing Windows scaling issues on the Surface Pro", "url": "/posts/Fixing-The-Surface-And-Windows-Scaling/", "categories": "Windows", "tags": "customization", "date": "2019-07-18 00:00:00 +0200", "snippet": "We all know that scaling on Windows has … some issues. If you use a Surface Device and Surface dock’s a lot you’ll run in to countless situations where you need the famous CRTL+WIN+ALT+B shortcut thank me later.So, the biggest problem comes when you’re using screens that are scaled differently. for example, if screen 1 is at 125% and screen 2 is at 200% windows will have to try it’s best to keep them coherent. a way around this is of course to set all the screens to the same scaling. Wich in turn will A: make everything tiny, or B wont make the best use of your nice Surface device …Here is a small guide for the later Install CRU tool to add a custom resloution to your Surface display link Add said resolution, in my case it is 1440x960 REBOOT Select the custom resolution and set scaling to 100% Small side note, Windows will somethimes ‘resset’ your resoloution when connection to new displays." }, { "title": "Fixing broken YUM REPO&#39;s on CentOS", "url": "/posts/restoring-yum-repos-centos/", "categories": "Linux", "tags": "cli", "date": "2019-07-02 00:00:00 +0200", "snippet": "Imagine this# yum updatehttps://mirrors.lug.mtu.edu/epel/7/x86_64/repodata/13b91b1efe2a1db71aa132d76383fdb5311887958a910548546d58a5856e2c5d-primary.sqlite.xz: [Errno 14] HTTPS Error 404 - Not FoundTrying other mirror.http://mirror.oss.ou.edu/epel/7/x86_64/repodata/13b91b1efe2a1db71aa132d76383fdb5311887958a910548546d58a5856e2c5d-primary.sqlite.xz: [Errno 14] HTTP Error 404 - Not FoundTrying other mirror.https://mirror.csclub.uwaterloo.ca/fedora/epel/7/x86_64/repodata/13b91b1efe2a1db71aa132d76383fdb5311887958a910548546d58a5856e2c5d-primary.sqlite.xz: [Errno 14] HTTPS Error 404 - Not FoundTrying other mirror.http://mirror.sfo12.us.leaseweb.net/epel/7/x86_64/repodata/13b91b1efe2a1db71aa132d76383fdb5311887958a910548546d58a5856e2c5d-primary.sqlite.xz: [Errno 14] HTTP Error 404 - Not FoundTrying other mirror.And this# yum updaterpmdb: page 6849: illegal page type or formatrpmdb: PANIC: Invalid argumentrpmdb: Packages: pgin failed for page 6758error: db4 error(-9494) from dbcursor-&amp;gt;c_get: DB_RUNRECOVERY: Fatal error, run database recoveryI know right ¯\\(ツ)/¯So it seems your mirror’s are broken, the package DB is out of date and you’re not that happy. Let’s go trough the steps of fixing this. We gonna do this in two steps: Cleaning the current repo’s &amp;amp; Cleaning the Package DB; Finding and installing the appropriate repo’sCleaning the current Repo’sFirst we will move the old package DB and clean the cache with these 3 command’smv /var/lib/rpm/__db* /tmp/rpm --rebuilddbyum clean allNow remove the old Repo’srm -r /etc/yum.repos.d/*rm /etc/yum.repos.d/*.repoFinding and installing the appropriate repo’sNow the next part is abit manual. You’ll need to find the appropriate RPM package to fix our repo’s. You can get them at the CentOS vault page: http://vault.centos.org . I’m working with CentOS build 1611 here so I used: http://vault.centos.org/7.3.1611/os/x86_64/Packages/centos-release-7-3.1611.el7.centos.x86_64.rpmIf you’re unsure on what version you are use cat /etc/centos-release to find out.Now install the repo using:rpm -Uvh --force http://vault.centos.org/7.3.1611/os/x86_64/Packages/centos-release-7-3.1611.el7.centos.x86_64.rpm And now you can run the command’s to verrify:yum makecache fastyum update" }, { "title": "Adding Az Context to PowerShell", "url": "/posts/az-context-at-prompt/", "categories": "Windows", "tags": "azure", "date": "2019-04-02 00:00:00 +0200", "snippet": "If you’re using Az command’s a lot an PowerShelling to different tenant’s you probably already have Context saving turnt off. If not, you might want to run it with:Disable-AzContextAutosaveMore info over at Ms DocsWith Autosave disabled you don’t have to worry (or worry less) about starting a new PS session and firing off commands at the wron tenant. As a extra security measue (and to prevent me from getting confused) I also added a small context aware script to my $PROFILE. If you’re not familiar with $PROFILE , it’s the file that get’s loaded every time you open u a new Powershell window. There is a chance you don’t have one yet. In that case you can create it by using:if (!(Test-Path -Path $PROFILE )) { New-Item -Type File -Path $PROFILE -Force }notepad $PROFILENow on to edeting the $PROFILE. Add the following code to it:function Check-AzCon { #Check connection to Azure $Context = Get-AzContext if($Context) { $Warn = &quot;Connected to &quot; + $Context.Tenant.Id + &quot; with account &quot; + $Context.Account.Id Write-Warning $Warn -WarningAction Inquire }}Check-AzConNow, if you open up a new Powershell window and you might still be connected to a remote Azure tenant it will let you know (:Quick bonus tip, you can always reload your current PS Profile with &amp;amp; $profile" }, { "title": "Bye bye Caps Lock - Re-mapping Caps to CTRL", "url": "/posts/bye-bye-caps-lock/", "categories": "Windows", "tags": "customization", "date": "2019-03-25 00:00:00 +0100", "snippet": "HOW OFTEN DO YOU USE CAPS LOCK? Not a lot right. So let’s re-map that key. In my setup I like to use the Caps Lock as 2nd CTRL key. This way I don’t have to fold up my pinky to use that ow so important CTRL+C &amp;amp; CTRL+V.That being said and done. Let’s get going. Changing the mapping requires you to edit some REG’s. Using the following lines this will be done automatically:$hexified = &quot;00,00,00,00,00,00,00,00,02,00,00,00,1d,00,3a,00,00,00,00,00&quot;.Split(&#39;,&#39;) | % { &quot;0x$_&quot;};$kbLayout = &#39;HKLM:\\System\\CurrentControlSet\\Control\\Keyboard Layout&#39;;New-ItemProperty -Path $kbLayout -Name &quot;Scancode Map&quot; -PropertyType Binary -Value ([byte[]]$hexified);After that a quick reboot loads up the new defaults.And hey, if you still need some text in ALL CAPS. Use Shoutcloud." } ]
